{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ni tes dengan template\n",
    "# sr = 44100\n",
    "# n_fft = 1024 # 23ms = n_fft / sr\n",
    "# hop_length = 512 # 10ms = hop_length / sr\n",
    "import librosa\n",
    "import noisereduce as nr\n",
    "import numpy as np\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import cosine\n",
    "import os\n",
    "\n",
    "# Function to apply bandpass filter\n",
    "def bandpass_filter(data, lowcut, highcut, fs, order):\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    y_filtered = lfilter(b, a, data)\n",
    "    return y_filtered\n",
    "\n",
    "\n",
    "def remove_silence(y):\n",
    "     # Memisahkan audio menjadi bagian-bagian berdasarkan energi\n",
    "    parts = librosa.effects.split(y, top_db=25, frame_length=1024, hop_length=512)\n",
    "\n",
    "    # Menggabungkan bagian-bagian yang tidak diam\n",
    "    y_non_silent = []\n",
    "    for start, end in parts:\n",
    "        y_non_silent.extend(y[start:end])\n",
    "\n",
    "    # Mengubah list menjadi array numpy\n",
    "    y = np.array(y_non_silent)\n",
    "    return y\n",
    "\n",
    "def preprocessing(audio):\n",
    "    y , sr = librosa.load(audio, sr=44100)\n",
    "    # y = librosa.util.normalize(y)\n",
    "    y = y/np.max(np.abs(y))\n",
    "    y = remove_silence(y)\n",
    "    y = nr.reduce_noise(y, sr, prop_decrease=0.5)\n",
    "    # y = bandpass_filter(y, lowcut=100.0, highcut=3000.0, fs=sr, order=5)\n",
    "    # y = shift_pitch_audio(y, sr)\n",
    "\n",
    "    return y,sr\n",
    "\n",
    "def extraction(audio):\n",
    "    y , sr = preprocessing(audio)\n",
    "    y = librosa.effects.preemphasis(y)\n",
    "    mfccs = librosa.feature.mfcc(y=y,\n",
    "                                 sr=sr,\n",
    "                                 n_mfcc=13,\n",
    "                                 window='hamming',\n",
    "                                 win_length=1024,\n",
    "                                 htk=False,\n",
    "                                 hop_length=512,\n",
    "                                 n_fft=1024,\n",
    "                                 norm='ortho',\n",
    "                                 dct_type=2,\n",
    "                                 n_mels=20)\n",
    "    # return = librosa.util.normalize(mfccs.T)\n",
    "    return mfccs.T\n",
    "def calculate_dtw(mfccs1, mfccs2):\n",
    "    distance, _ = fastdtw(mfccs1, mfccs2, dist=cosine)\n",
    "    return distance\n",
    "\n",
    "def main(input_mfcc, template_mfcc, output_file, input_audio_name, template_score, max_threshold_score):\n",
    "    final_score = 0\n",
    "\n",
    "    with open(output_file, 'a') as f:  # Menggunakan mode 'a' untuk append\n",
    "        # Hitung jarak antara input dan template menggunakan DTW\n",
    "        distance = calculate_dtw(input_mfcc, template_mfcc)\n",
    "\n",
    "        # Hitung selisih antara jarak dan nilai template\n",
    "        dif_distance = distance - template_score\n",
    "\n",
    "        # Normalisasi selisih antara 0 dan 1\n",
    "        normalized_dif_distance = (dif_distance - 0) / (max_threshold_score - 0)\n",
    "\n",
    "        # Hitung skor berdasarkan selisih yang dinormalisasi\n",
    "        final_score = int(100 - (normalized_dif_distance * 100))\n",
    "\n",
    "        # Pastikan skor berada dalam rentang 0-100\n",
    "        final_score = max(min(final_score, 100), 0)\n",
    "\n",
    "        # Tulis nama audio dan hasil jarak ke file\n",
    "        f.write(f\"Audio Name: {input_audio_name}\\n\")\n",
    "        f.write(f\"Distance = {distance}\\n\")\n",
    "        # f.write(f\"Difference Distance = {dif_distance}\\n\")\n",
    "        # f.write(f\"Final Score = {final_score}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        print(f\"Audio Name: {input_audio_name}\")\n",
    "        print(f\"Distance = {distance}\\n\")\n",
    "        # print(f\"Difference Distance = {dif_distance}\\n\")\n",
    "        # print(f\"final score = {final_score}\\n\")\n",
    "\n",
    "# List of audio files and their names\n",
    "list_of_audio_files = [\n",
    "    (\"../Dataset/Testing_Rafi/rafi_shad.wav\", \"rafi_shad\"),\n",
    "    (\"../Dataset/Ridho_mic/Ridho_shad.wav\", \"ridho_shad\"),\n",
    "    (\"../Dataset/Dona_mic/.wav\", \"ridho_shad\")\n",
    "]\n",
    "\n",
    "# Output file path\n",
    "# output_file = \"../hasil_testing_template/newpre_testing_non_norm_template_shad.txt\"\n",
    "output_file = \"../hasil_testing_template/testing_langsung_mfcc.txt\"\n",
    "\n",
    "# Load template MFCC\n",
    "# template_mfcc_path = \"../new_hasil_template_mfcc/newpre_non_norm_template_shad.csv\"\n",
    "template_mfcc_path = \"../new_hasil_template_mfcc/shad_mfcc_1.csv\"\n",
    "template_mfcc = np.loadtxt(template_mfcc_path, delimiter=\",\")\n",
    "# template_mfcc = librosa.util.normalize(template_mfcc)\n",
    "\n",
    "# Threshold scores\n",
    "template_score = 309.962\n",
    "max_threshold_score = 150\n",
    "with open(output_file, 'w') as f:\n",
    "        f.write('')\n",
    "\n",
    "# Write header to the output file\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(\"Hasil Banding Template new preprocessing:\\n\\n\")\n",
    "\n",
    "# Iterate over audio files\n",
    "for input_file_audio, input_audio_name in list_of_audio_files:\n",
    "    # Extract MFCC from current audio file\n",
    "    input_mfcc = extraction(input_file_audio)\n",
    "\n",
    "    # Call main function for current audio file\n",
    "    main(input_mfcc, template_mfcc, output_file, input_audio_name, template_score, max_threshold_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Folder = 01.Ha'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 104>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# Iterate over each audio file\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m audio_input, audio_name \u001b[38;5;129;01min\u001b[39;00m list_of_audio_files:\n\u001b[1;32m--> 119\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_threshold_score\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(file_input, audio_name, folder_template, output_file, template_score, max_threshold_score)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m template \u001b[38;5;129;01min\u001b[39;00m templates:\n\u001b[0;32m     64\u001b[0m     audio_template \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_template, template)\n\u001b[1;32m---> 66\u001b[0m     mfccs1 \u001b[38;5;241m=\u001b[39m \u001b[43mextraction\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m     mfccs2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mloadtxt(audio_template, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     69\u001b[0m     dtw_distance \u001b[38;5;241m=\u001b[39m calculate_dtw(mfccs1, mfccs2)\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mextraction\u001b[1;34m(audio)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextraction\u001b[39m(audio):\n\u001b[1;32m---> 39\u001b[0m     y, sr \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessing\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m     mfccs \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mmfcc(y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m     41\u001b[0m                                  sr\u001b[38;5;241m=\u001b[39msr,\n\u001b[0;32m     42\u001b[0m                                  n_mfcc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m13\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m                                  dct_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m     50\u001b[0m                                  n_mels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mfccs\u001b[38;5;241m.\u001b[39mT\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mpreprocessing\u001b[1;34m(audio)\u001b[0m\n\u001b[0;32m     33\u001b[0m y \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(np\u001b[38;5;241m.\u001b[39mabs(y))\n\u001b[0;32m     34\u001b[0m y \u001b[38;5;241m=\u001b[39m remove_silence(y)\n\u001b[1;32m---> 35\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mnr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce_noise\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprop_decrease\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y, sr\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\noisereduce\\noisereduce.py:190\u001b[0m, in \u001b[0;36mreduce_noise\u001b[1;34m(y, sr, stationary, y_noise, prop_decrease, time_constant_s, freq_mask_smooth_hz, time_mask_smooth_ms, thresh_n_mult_nonstationary, sigmoid_slope_nonstationary, n_std_thresh_stationary, tmp_folder, chunk_size, padding, n_fft, win_length, hop_length, clip_noise_stationary, use_tqdm, n_jobs, use_torch, device)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    172\u001b[0m         sg \u001b[38;5;241m=\u001b[39m SpectralGateNonStationary(\n\u001b[0;32m    173\u001b[0m             y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    174\u001b[0m             sr\u001b[38;5;241m=\u001b[39msr,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    188\u001b[0m             n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    189\u001b[0m         )\n\u001b[1;32m--> 190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_traces\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\noisereduce\\spectralgate\\base.py:222\u001b[0m, in \u001b[0;36mSpectralGate.get_traces\u001b[1;34m(self, start_frame, end_frame)\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    220\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m filtered_chunk\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype)\n\u001b[1;32m--> 222\u001b[0m filtered_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_frame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_frame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_frame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflat:\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m filtered_chunk\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype)\u001b[38;5;241m.\u001b[39mflatten()\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\noisereduce\\spectralgate\\base.py:149\u001b[0m, in \u001b[0;36mSpectralGate.filter_chunk\u001b[1;34m(self, start_frame, end_frame)\u001b[0m\n\u001b[0;32m    147\u001b[0m i2 \u001b[38;5;241m=\u001b[39m end_frame \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding\n\u001b[0;32m    148\u001b[0m padded_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_chunk(i1, i2)\n\u001b[1;32m--> 149\u001b[0m filtered_padded_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpadded_chunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m filtered_padded_chunk[:, start_frame \u001b[38;5;241m-\u001b[39m i1: end_frame \u001b[38;5;241m-\u001b[39m i1]\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\noisereduce\\spectralgate\\nonstationary.py:101\u001b[0m, in \u001b[0;36mSpectralGateNonStationary._do_filter\u001b[1;34m(self, chunk)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_filter\u001b[39m(\u001b[38;5;28mself\u001b[39m, chunk):\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;124;03m\"\"\"Do the actual filtering\"\"\"\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m     chunk_filtered \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspectral_gating_nonstationary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m chunk_filtered\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\noisereduce\\spectralgate\\nonstationary.py:91\u001b[0m, in \u001b[0;36mSpectralGateNonStationary.spectral_gating_nonstationary\u001b[1;34m(self, chunk)\u001b[0m\n\u001b[0;32m     88\u001b[0m     sig_stft_denoised \u001b[38;5;241m=\u001b[39m sig_stft \u001b[38;5;241m*\u001b[39m sig_mask\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;66;03m# invert/recover the signal\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m     denoised_signal \u001b[38;5;241m=\u001b[39m \u001b[43mistft\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43msig_stft_denoised\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hop_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwin_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_win_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     denoised_channels[ci, : \u001b[38;5;28mlen\u001b[39m(denoised_signal)] \u001b[38;5;241m=\u001b[39m denoised_signal\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m denoised_channels\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\util\\decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[0;32m     91\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[38;5;241m-\u001b[39mextra_args:])\n\u001b[0;32m     94\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\core\\spectrum.py:394\u001b[0m, in \u001b[0;36mistft\u001b[1;34m(stft_matrix, hop_length, win_length, n_fft, window, center, dtype, length)\u001b[0m\n\u001b[0;32m    391\u001b[0m     n_frames \u001b[38;5;241m=\u001b[39m stft_matrix\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 394\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype_c2r\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstft_matrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    396\u001b[0m shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(stft_matrix\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m    397\u001b[0m expected_signal_len \u001b[38;5;241m=\u001b[39m n_fft \u001b[38;5;241m+\u001b[39m hop_length \u001b[38;5;241m*\u001b[39m (n_frames \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\util\\decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[0;32m     91\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[38;5;241m-\u001b[39mextra_args:])\n\u001b[0;32m     94\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\util\\utils.py:2185\u001b[0m, in \u001b[0;36mdtype_c2r\u001b[1;34m(d, default)\u001b[0m\n\u001b[0;32m   2138\u001b[0m \u001b[38;5;129m@deprecate_positional_args\u001b[39m\n\u001b[0;32m   2139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdtype_c2r\u001b[39m(d, \u001b[38;5;241m*\u001b[39m, default\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32):\n\u001b[0;32m   2140\u001b[0m     \u001b[38;5;124;03m\"\"\"Find the real numpy dtype corresponding to a complex dtype.\u001b[39;00m\n\u001b[0;32m   2141\u001b[0m \n\u001b[0;32m   2142\u001b[0m \u001b[38;5;124;03m    This is used to maintain numerical precision and memory footprint\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2180\u001b[0m \u001b[38;5;124;03m    dtype('float64')\u001b[39;00m\n\u001b[0;32m   2181\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   2182\u001b[0m     mapping \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   2183\u001b[0m         np\u001b[38;5;241m.\u001b[39mdtype(np\u001b[38;5;241m.\u001b[39mcomplex64): np\u001b[38;5;241m.\u001b[39mfloat32,\n\u001b[0;32m   2184\u001b[0m         np\u001b[38;5;241m.\u001b[39mdtype(np\u001b[38;5;241m.\u001b[39mcomplex128): np\u001b[38;5;241m.\u001b[39mfloat64,\n\u001b[1;32m-> 2185\u001b[0m         np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;28mcomplex\u001b[39m): np\u001b[38;5;241m.\u001b[39mdtype(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m)\u001b[38;5;241m.\u001b[39mtype,\n\u001b[0;32m   2186\u001b[0m     }\n\u001b[0;32m   2188\u001b[0m     \u001b[38;5;66;03m# If we're given a real type already, return it\u001b[39;00m\n\u001b[0;32m   2189\u001b[0m     dt \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(d)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\__init__.py:338\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    333\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    334\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    335\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[1;32m--> 338\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtesting\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "# tes\n",
    "\n",
    "# sr = 44100\n",
    "# n_fft = 1024 # 23ms = n_fft / sr\n",
    "# hop_length = 512 # 10ms = hop_length / sr\n",
    "import librosa\n",
    "import noisereduce as nr\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import cosine\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from scipy.signal import butter, lfilter\n",
    "from IPython.display import clear_output\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def remove_silence(y):\n",
    "    # Memisahkan audio menjadi bagian-bagian berdasarkan energi\n",
    "    parts = librosa.effects.split(y, top_db=25, frame_length=1024, hop_length=512)\n",
    "\n",
    "    # Menggabungkan bagian-bagian yang tidak diam\n",
    "    y_non_silent = []\n",
    "    for start, end in parts:\n",
    "        y_non_silent.extend(y[start:end])\n",
    "\n",
    "    # Mengubah list menjadi array numpy\n",
    "    y = np.array(y_non_silent)\n",
    "    return y\n",
    "\n",
    "def preprocessing(audio):\n",
    "    y, sr = librosa.load(audio, sr=44100)\n",
    "    y = librosa.effects.preemphasis(y)\n",
    "    y = y / np.max(np.abs(y))\n",
    "    y = remove_silence(y)\n",
    "    y = nr.reduce_noise(y, sr, prop_decrease=0.8)\n",
    "    return y, sr\n",
    "\n",
    "def extraction(audio):\n",
    "    y, sr = preprocessing(audio)\n",
    "    mfccs = librosa.feature.mfcc(y=y,\n",
    "                                 sr=sr,\n",
    "                                 n_mfcc=13,\n",
    "                                 window='hamming',\n",
    "                                 win_length=1024,\n",
    "                                 htk=True,\n",
    "                                 hop_length=512,\n",
    "                                 n_fft=1024,\n",
    "                                 norm=None,\n",
    "                                 dct_type=2,\n",
    "                                 n_mels=20)\n",
    "    return mfccs.T\n",
    "\n",
    "def calculate_dtw(mfccs1, mfccs2):\n",
    "    distance, _ = fastdtw(mfccs1, mfccs2, dist=cosine)\n",
    "    return distance\n",
    "\n",
    "def main(file_input, audio_name, folder_template, output_file, template_score, max_threshold_score):\n",
    "    audio_input = file_input\n",
    "    templates = os.listdir(folder_template)\n",
    "    total_distances = 0\n",
    "\n",
    "    with open(output_file, 'a') as f:\n",
    "        for template in templates:\n",
    "            audio_template = os.path.join(folder_template, template)\n",
    "\n",
    "            mfccs1 = extraction(audio_input)\n",
    "            mfccs2 = np.loadtxt(audio_template, delimiter=',')\n",
    "\n",
    "            dtw_distance = calculate_dtw(mfccs1, mfccs2)\n",
    "            total_distances += dtw_distance\n",
    "\n",
    "        f.write(audio_name)\n",
    "        print(audio_name)\n",
    "        f.write(f\"\\nTotal Distance = {total_distances}\\n\")\n",
    "        print(f\"\\nTotal Distance = {total_distances}\\n\")\n",
    "\n",
    "        average_distance = total_distances / len(templates)\n",
    "        f.write(f\"Average Distance = {average_distance}\\n\")\n",
    "        print(f\"Average Distance = {average_distance}\\n\")\n",
    "\n",
    "\n",
    "root = \"../Dataset_MFCC_95prem/\"\n",
    "\n",
    "list_template_folders = [\n",
    "    (\"01.Ha'/\"),\n",
    "    # (\"02.Kha'/\"),\n",
    "    # (\"03.Shad/\"),\n",
    "    # (\"04.Dhad/\"),\n",
    "    # (\"05.Tha'/\"),\n",
    "    # (\"06.Dhza'/\"),\n",
    "    # (\"07.'AIn/\"),\n",
    "    # (\"08.Ghain/\"),\n",
    "    # (\"09.Qaf/\"),\n",
    "    # (\"10.Ha^'/\")\n",
    "]\n",
    "# List of audio files and their names\n",
    "list_of_audio_files = [\n",
    "    (\"../Dataset/Testing_Rafi/rafi_Ha'.wav\", \"rafi_Ha'\"),\n",
    "    (\"../Dataset/Ridho_mic/Ridho_Ha'.wav\", \"ridho_Ha'\"),\n",
    "    (\"../Dataset/Dona_mic/Ha'_F1_14.wav\", \"F1_Ha'\"),\n",
    "    (\"../Dataset/Zahrah_mic/Ha'_F2_14.wav\", \"F2_Ha'\")\n",
    "]\n",
    "\n",
    "for folder in list_template_folders:\n",
    "    clear_output()\n",
    "    template_folder = os.path.join(root, folder)\n",
    "\n",
    "    output_file = f\"../fix_hasil_testing/tes.txt\"\n",
    "\n",
    "    template_score = 23.004\n",
    "    max_threshold_score = 5\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write('')\n",
    "        f.write(f\"Banding {folder.strip('/')} dengan tester\\n\")\n",
    "    print(f\"Processing Folder = {folder.strip('/')}\")\n",
    "    # Iterate over each audio file\n",
    "    for audio_input, audio_name in list_of_audio_files:\n",
    "        main(audio_input, audio_name, template_folder, output_file, template_score, max_threshold_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Folder = 01.Ha'\n",
      "rafi_Ha'\n",
      "\n",
      "Total Distance = 355.5269541834126\n",
      "\n",
      "Average Distance = 19.751497454634034\n",
      "\n",
      "ridho_Ha'\n",
      "\n",
      "Total Distance = 384.24146453766843\n",
      "\n",
      "Average Distance = 21.34674802987047\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 148>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# Iterate over each audio file\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m audio_input, audio_name \u001b[38;5;129;01min\u001b[39;00m list_of_audio_files:\n\u001b[1;32m--> 163\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43maudio_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_threshold_score\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(file_input, audio_name, folder_template, output_file, template_score, max_threshold_score)\u001b[0m\n\u001b[0;32m     79\u001b[0m mfccs2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mloadtxt(audio_template,delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# mfccs2 = mfccs2.T\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# mfccs2 = mfccs2[1:]\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# mfccs2 = mfccs2.T\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# print(f\"mfccs2.shape = {mfccs2.shape}\")\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m# f.write(f\"mfccs2.shape = {mfccs2.shape}\")\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m dtw_distance \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_dtw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmfccs1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmfccs2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# print(f\"dtw_distance = {dtw_distance}\")\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# f.write(f\"dtw_distance = {dtw_distance}\")\u001b[39;00m\n\u001b[0;32m     94\u001b[0m total_distances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m dtw_distance\n",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36mcalculate_dtw\u001b[1;34m(mfccs1, mfccs2)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_dtw\u001b[39m(mfccs1, mfccs2):\n\u001b[1;32m---> 65\u001b[0m     distance, _ \u001b[38;5;241m=\u001b[39m \u001b[43mfastdtw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmfccs1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmfccs2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcosine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m distance\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fastdtw\\fastdtw.py:53\u001b[0m, in \u001b[0;36mfastdtw\u001b[1;34m(x, y, radius, dist)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m''' return the approximate distance between 2 time series with O(N)\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m    time and memory complexity\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    (2.0, [(0, 0), (1, 0), (2, 1), (3, 2), (4, 2)])\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     52\u001b[0m x, y, dist \u001b[38;5;241m=\u001b[39m __prep_inputs(x, y, dist)\n\u001b[1;32m---> 53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m__fastdtw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdist\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fastdtw\\fastdtw.py:75\u001b[0m, in \u001b[0;36m__fastdtw\u001b[1;34m(x, y, radius, dist)\u001b[0m\n\u001b[0;32m     72\u001b[0m distance, path \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m     73\u001b[0m     __fastdtw(x_shrinked, y_shrinked, radius\u001b[38;5;241m=\u001b[39mradius, dist\u001b[38;5;241m=\u001b[39mdist)\n\u001b[0;32m     74\u001b[0m window \u001b[38;5;241m=\u001b[39m __expand_window(path, \u001b[38;5;28mlen\u001b[39m(x), \u001b[38;5;28mlen\u001b[39m(y), radius)\n\u001b[1;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m__dtw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdist\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fastdtw\\fastdtw.py:141\u001b[0m, in \u001b[0;36m__dtw\u001b[1;34m(x, y, window, dist)\u001b[0m\n\u001b[0;32m    139\u001b[0m D[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m window:\n\u001b[1;32m--> 141\u001b[0m     dt \u001b[38;5;241m=\u001b[39m \u001b[43mdist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m     D[i, j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m((D[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, j][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39mdt, i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, j), (D[i, j\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39mdt, i, j\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    143\u001b[0m                   (D[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, j\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39mdt, i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, j\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m a: a[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    144\u001b[0m path \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\spatial\\distance.py:695\u001b[0m, in \u001b[0;36mcosine\u001b[1;34m(u, v, w)\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;124;03mCompute the Cosine distance between 1-D arrays.\u001b[39;00m\n\u001b[0;32m    655\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    690\u001b[0m \n\u001b[0;32m    691\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;66;03m# cosine distance is also referred to as 'uncentered correlation',\u001b[39;00m\n\u001b[0;32m    693\u001b[0m \u001b[38;5;66;03m#   or 'reflective correlation'\u001b[39;00m\n\u001b[0;32m    694\u001b[0m \u001b[38;5;66;03m# clamp the result to 0-2\u001b[39;00m\n\u001b[1;32m--> 695\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmin\u001b[39m(\u001b[43mcorrelation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcentered\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m, \u001b[38;5;241m2.0\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\spatial\\distance.py:625\u001b[0m, in \u001b[0;36mcorrelation\u001b[1;34m(u, v, w, centered)\u001b[0m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcorrelation\u001b[39m(u, v, w\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, centered\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;124;03m    Compute the correlation distance between two 1-D arrays.\u001b[39;00m\n\u001b[0;32m    578\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;124;03m    0.5\u001b[39;00m\n\u001b[0;32m    624\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 625\u001b[0m     u \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    626\u001b[0m     v \u001b[38;5;241m=\u001b[39m _validate_vector(v)\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\spatial\\distance.py:299\u001b[0m, in \u001b[0;36m_validate_vector\u001b[1;34m(u, dtype)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_vector\u001b[39m(u, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;66;03m# XXX Is order='c' really necessary?\u001b[39;00m\n\u001b[1;32m--> 299\u001b[0m     u \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m u\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m u\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ini tes banding mfcc per audio langsung dtw\n",
    "\n",
    "# sr = 44100\n",
    "# n_fft = 1024 # 23ms = n_fft / sr\n",
    "# hop_length = 512 # 10ms = hop_length / sr\n",
    "import librosa\n",
    "import noisereduce as nr\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import cosine\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from scipy.signal import butter, lfilter\n",
    "from IPython.display import clear_output\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def remove_silence(y):\n",
    "     # Memisahkan audio menjadi bagian-bagian berdasarkan energi\n",
    "    parts = librosa.effects.split(y, top_db=25, frame_length=1024, hop_length=512)\n",
    "\n",
    "    # Menggabungkan bagian-bagian yang tidak diam\n",
    "    y_non_silent = []\n",
    "    for start, end in parts:\n",
    "        y_non_silent.extend(y[start:end])\n",
    "\n",
    "    # Mengubah list menjadi array numpy\n",
    "    y = np.array(y_non_silent)\n",
    "    return y\n",
    "\n",
    "def preprocessing(audio):\n",
    "    y , sr = librosa.load(audio, sr=44100)\n",
    "    y = librosa.effects.preemphasis(y)\n",
    "    y = y/np.max(np.abs(y))\n",
    "    y = remove_silence(y)\n",
    "    y = nr.reduce_noise(y, sr, prop_decrease=0.8)\n",
    "    return y,sr\n",
    "\n",
    "def extraction(audio):\n",
    "    y , sr = preprocessing(audio)\n",
    "    # y = librosa.effects.preemphasis(y)\n",
    "    mfccs = librosa.feature.mfcc(y=y,\n",
    "                                 sr=sr,\n",
    "                                 n_mfcc=13,\n",
    "                                 window='hamming',\n",
    "                                 win_length=1024,\n",
    "                                 htk=True,\n",
    "                                 hop_length=512,\n",
    "                                 n_fft=1024,\n",
    "                                 norm=None,\n",
    "                                 dct_type=2,\n",
    "                                 n_mels=20)\n",
    "    # mfccs = mfccs[1:]\n",
    "    # mfccs = librosa.util.normalize(mfccs, axis=1 )\n",
    "    # return = librosa.util.normalize(mfccs.T)\n",
    "    return mfccs.T\n",
    "\n",
    "\n",
    "def apply_pca(mfcc_features, n_components):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(mfcc_features)\n",
    "    mfcc_pca = pca.transform(mfcc_features)\n",
    "    return mfcc_pca\n",
    "\n",
    "def calculate_dtw(mfccs1, mfccs2):\n",
    "    distance, _ = fastdtw(mfccs1, mfccs2, dist=cosine)\n",
    "    return distance\n",
    "\n",
    "def main(file_input, audio_name, folder_template, output_file, template_score, max_threshold_score):\n",
    "    audio_input = file_input\n",
    "    templates = os.listdir(folder_template)\n",
    "    # print(f\"len templates = {len(templates)}\")\n",
    "    total_distances = 0\n",
    "\n",
    "    with open(output_file, 'a') as f:\n",
    "        for template in templates:\n",
    "            audio_template = os.path.join(folder_template, template)\n",
    "\n",
    "            mfccs1 = extraction(audio_input)\n",
    "            mfccs2 = np.loadtxt(audio_template,delimiter=',')\n",
    "            # mfccs2 = mfccs2.T\n",
    "            # mfccs2 = mfccs2[1:]\n",
    "            # mfccs2 = mfccs2.T\n",
    "\n",
    "            # mfccs1 = apply_pca(mfccs1,10)\n",
    "            # mfccs2 = apply_pca(mfccs2,10)\n",
    "            # print(f\"mfccs1.shape = {mfccs1.shape}\")\n",
    "            # f.write(f\"mfccs1.shape = {mfccs1.shape}\")\n",
    "            # print(f\"mfccs2.shape = {mfccs2.shape}\")\n",
    "            # f.write(f\"mfccs2.shape = {mfccs2.shape}\")\n",
    "\n",
    "            dtw_distance = calculate_dtw(mfccs1, mfccs2)\n",
    "            # print(f\"dtw_distance = {dtw_distance}\")\n",
    "            # f.write(f\"dtw_distance = {dtw_distance}\")\n",
    "            total_distances += dtw_distance\n",
    "\n",
    "            # result_line = f\"Jarak DTW antara {audio_input} dan {template}: {dtw_distance}\\n\"\n",
    "            # f.write(result_line)\n",
    "\n",
    "        # Tulis hasil total jarak ke file\n",
    "        f.write(audio_name)\n",
    "        print(audio_name)\n",
    "        f.write(f\"\\nTotal Distance = {total_distances}\\n\")\n",
    "        print(f\"\\nTotal Distance = {total_distances}\\n\")\n",
    "\n",
    "        # Hitung rata-rata jarak\n",
    "        average_distance = total_distances / len(templates)\n",
    "        f.write(f\"Average Distance = {average_distance}\\n\")\n",
    "        print(f\"Average Distance = {average_distance}\\n\")\n",
    "        # # Hitung selisih antara rata-rata jarak dengan nilai template\n",
    "        # dif_distance = average_distance - template_score\n",
    "        # f.write(f\"Difference Distance = {dif_distance}\\n\")\n",
    "\n",
    "        # # Hitung skor akhir berdasarkan selisih\n",
    "        # if dif_distance <= 0:\n",
    "        #     final_score = 100\n",
    "        # elif dif_distance >= max_threshold_score:\n",
    "        #     final_score = 0\n",
    "        # else:\n",
    "        #     final_score = int(100 - ((dif_distance / max_threshold_score) * 100))\n",
    "        \n",
    "        # f.write(f\"Final Score = {final_score}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "root = \"../Dataset_MFCC_noprem/\"\n",
    "\n",
    "list_template_folders = [\n",
    "    (\"01.Ha'/\"),\n",
    "    (\"02.Kha'/\"),\n",
    "    (\"03.Shad/\"),\n",
    "    (\"04.Dhad/\"),\n",
    "    (\"05.Tha'/\"),\n",
    "    (\"06.Dhza'/\"),\n",
    "    (\"07.'AIn/\"),\n",
    "    (\"08.Ghain/\"),\n",
    "    (\"09.Qaf/\"),\n",
    "    (\"10.Ha^'/\")\n",
    "]\n",
    "# List of audio files and their names\n",
    "list_of_audio_files = [\n",
    "    (\"../Dataset/Testing_Rafi/rafi_Ha'.wav\", \"rafi_Ha'\"),\n",
    "    (\"../Dataset/Ridho_mic/Ridho_Ha'.wav\", \"ridho_Ha'\"),\n",
    "    (\"../Dataset/Dona_mic/Ha'_F1_14.wav\", \"F1_Ha'\"),\n",
    "    (\"../Dataset/Zahrah_mic/Ha'_F2_14.wav\", \"F2_Ha'\")\n",
    "]\n",
    "\n",
    "for folder in list_template_folders:\n",
    "    clear_output()\n",
    "    template_folder = os.path.join(root, folder)\n",
    "\n",
    "    output_file = f\"../fix_hasil_testing/noprem_testing_Ha'_template_{folder.strip('/')}.txt\"\n",
    "\n",
    "    template_score = 23.004\n",
    "    max_threshold_score = 5\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "            f.write('')\n",
    "            f.write(f\"Banding {folder.strip('/')} dengan tester\\n\")\n",
    "    print(f\"Processing Folder = {folder.strip('/')}\")\n",
    "    # Iterate over each audio file\n",
    "    for audio_input, audio_name in list_of_audio_files:\n",
    "        main(audio_input,audio_name, template_folder, output_file, template_score, max_threshold_score)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Folder = 10.Ha^'\n",
      "rafi_kha'\n",
      "\n",
      "Total Distance = 322.71305947316057\n",
      "\n",
      "Average Distance = 17.928503304064478\n",
      "\n",
      "ridho_kha'\n",
      "\n",
      "Total Distance = 370.7166722496325\n",
      "\n",
      "Average Distance = 20.59537068053514\n",
      "\n",
      "F1_kha'\n",
      "\n",
      "Total Distance = 302.3054599157834\n",
      "\n",
      "Average Distance = 16.794747773099076\n",
      "\n",
      "F2_kha'\n",
      "\n",
      "Total Distance = 299.0364735225891\n",
      "\n",
      "Average Distance = 16.613137417921617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ini tes banding mfcc per audio langsung dtw\n",
    "\n",
    "# sr = 44100\n",
    "# n_fft = 1024 # 23ms = n_fft / sr\n",
    "# hop_length = 512 # 10ms = hop_length / sr\n",
    "import librosa\n",
    "import noisereduce as nr\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import cosine\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from scipy.signal import butter, lfilter\n",
    "from IPython.display import clear_output\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def remove_silence(y):\n",
    "     # Memisahkan audio menjadi bagian-bagian berdasarkan energi\n",
    "    parts = librosa.effects.split(y, top_db=25, frame_length=1024, hop_length=512)\n",
    "\n",
    "    # Menggabungkan bagian-bagian yang tidak diam\n",
    "    y_non_silent = []\n",
    "    for start, end in parts:\n",
    "        y_non_silent.extend(y[start:end])\n",
    "\n",
    "    # Mengubah list menjadi array numpy\n",
    "    y = np.array(y_non_silent)\n",
    "    return y\n",
    "\n",
    "def preprocessing(audio):\n",
    "    y , sr = librosa.load(audio, sr=44100)\n",
    "    y = librosa.effects.preemphasis(y)\n",
    "    y = y/np.max(np.abs(y))\n",
    "    y = remove_silence(y)\n",
    "    y = nr.reduce_noise(y, sr, prop_decrease=0.8)\n",
    "    return y,sr\n",
    "\n",
    "def extraction(audio):\n",
    "    y , sr = preprocessing(audio)\n",
    "    # y = librosa.effects.preemphasis(y)\n",
    "    mfccs = librosa.feature.mfcc(y=y,\n",
    "                                 sr=sr,\n",
    "                                 n_mfcc=13,\n",
    "                                 window='hamming',\n",
    "                                 win_length=1024,\n",
    "                                 htk=True,\n",
    "                                 hop_length=512,\n",
    "                                 n_fft=1024,\n",
    "                                 norm=None,\n",
    "                                 dct_type=2,\n",
    "                                 n_mels=20)\n",
    "    # mfccs = mfccs[1:]\n",
    "    # mfccs = librosa.util.normalize(mfccs, axis=1 )\n",
    "    # return = librosa.util.normalize(mfccs.T)\n",
    "    return mfccs.T\n",
    "\n",
    "\n",
    "def apply_pca(mfcc_features, n_components):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(mfcc_features)\n",
    "    mfcc_pca = pca.transform(mfcc_features)\n",
    "    return mfcc_pca\n",
    "\n",
    "def calculate_dtw(mfccs1, mfccs2):\n",
    "    distance, _ = fastdtw(mfccs1, mfccs2, dist=cosine)\n",
    "    return distance\n",
    "\n",
    "def main(file_input, audio_name, folder_template, output_file, template_score, max_threshold_score):\n",
    "    audio_input = file_input\n",
    "    templates = os.listdir(folder_template)\n",
    "    # print(f\"len templates = {len(templates)}\")\n",
    "    total_distances = 0\n",
    "\n",
    "    with open(output_file, 'a') as f:\n",
    "        for template in templates:\n",
    "            audio_template = os.path.join(folder_template, template)\n",
    "\n",
    "            mfccs1 = extraction(audio_input)\n",
    "            mfccs2 = np.loadtxt(audio_template,delimiter=',')\n",
    "            # mfccs2 = mfccs2.T\n",
    "            # mfccs2 = mfccs2[1:]\n",
    "            # mfccs2 = mfccs2.T\n",
    "\n",
    "            # mfccs1 = apply_pca(mfccs1,10)\n",
    "            # mfccs2 = apply_pca(mfccs2,10)\n",
    "            # print(f\"mfccs1.shape = {mfccs1.shape}\")\n",
    "            # f.write(f\"mfccs1.shape = {mfccs1.shape}\")\n",
    "            # print(f\"mfccs2.shape = {mfccs2.shape}\")\n",
    "            # f.write(f\"mfccs2.shape = {mfccs2.shape}\")\n",
    "\n",
    "            dtw_distance = calculate_dtw(mfccs1, mfccs2)\n",
    "            # print(f\"dtw_distance = {dtw_distance}\")\n",
    "            # f.write(f\"dtw_distance = {dtw_distance}\")\n",
    "            total_distances += dtw_distance\n",
    "\n",
    "            # result_line = f\"Jarak DTW antara {audio_input} dan {template}: {dtw_distance}\\n\"\n",
    "            # f.write(result_line)\n",
    "\n",
    "        # Tulis hasil total jarak ke file\n",
    "        f.write(audio_name)\n",
    "        print(audio_name)\n",
    "        f.write(f\"\\nTotal Distance = {total_distances}\\n\")\n",
    "        print(f\"\\nTotal Distance = {total_distances}\\n\")\n",
    "\n",
    "        # Hitung rata-rata jarak\n",
    "        average_distance = total_distances / len(templates)\n",
    "        f.write(f\"Average Distance = {average_distance}\\n\")\n",
    "        print(f\"Average Distance = {average_distance}\\n\")\n",
    "        # # Hitung selisih antara rata-rata jarak dengan nilai template\n",
    "        # dif_distance = average_distance - template_score\n",
    "        # f.write(f\"Difference Distance = {dif_distance}\\n\")\n",
    "\n",
    "        # # Hitung skor akhir berdasarkan selisih\n",
    "        # if dif_distance <= 0:\n",
    "        #     final_score = 100\n",
    "        # elif dif_distance >= max_threshold_score:\n",
    "        #     final_score = 0\n",
    "        # else:\n",
    "        #     final_score = int(100 - ((dif_distance / max_threshold_score) * 100))\n",
    "        \n",
    "        # f.write(f\"Final Score = {final_score}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "root = \"../Dataset_MFCC_prem_norm_non_ortho/\"\n",
    "\n",
    "list_template_folders = [\n",
    "    (\"01.Ha'/\"),\n",
    "    (\"02.Kha'/\"),\n",
    "    (\"03.Shad/\"),\n",
    "    (\"04.Dhad/\"),\n",
    "    (\"05.Tha'/\"),\n",
    "    (\"06.Dhza'/\"),\n",
    "    (\"07.'AIn/\"),\n",
    "    (\"08.Ghain/\"),\n",
    "    (\"09.Qaf/\"),\n",
    "    (\"10.Ha^'/\")\n",
    "]\n",
    "# List of audio files and their names\n",
    "list_of_audio_files = [\n",
    "    (\"../Dataset/Testing_Rafi/rafi_kha'.wav\", \"rafi_kha'\"),\n",
    "    (\"../Dataset/Ridho_mic/Ridho_kha'.wav\", \"ridho_kha'\"),\n",
    "    (\"../Dataset/Dona_mic/kha'_F1_14.wav\", \"F1_kha'\"),\n",
    "    (\"../Dataset/Zahrah_mic/kha'_F2_14.wav\", \"F2_kha'\")\n",
    "]\n",
    "\n",
    "for folder in list_template_folders:\n",
    "    clear_output()\n",
    "    template_folder = os.path.join(root, folder)\n",
    "\n",
    "    output_file = f\"../fix_hasil_testing/non_ortho_prem_norm_testing_kha'_template_{folder.strip('/')}.txt\"\n",
    "\n",
    "    template_score = 23.004\n",
    "    max_threshold_score = 5\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "            f.write('')\n",
    "            f.write(f\"Banding {folder.strip('/')} dengan tester\\n\")\n",
    "    print(f\"Processing Folder = {folder.strip('/')}\")\n",
    "    # Iterate over each audio file\n",
    "    for audio_input, audio_name in list_of_audio_files:\n",
    "        main(audio_input,audio_name, template_folder, output_file, template_score, max_threshold_score)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Folder = 10.Ha^'\n",
      "rafi_shad\n",
      "\n",
      "Total Distance = 648.8122227226581\n",
      "\n",
      "Average Distance = 36.04512348459212\n",
      "\n",
      "ridho_shad\n",
      "\n",
      "Total Distance = 457.86157894372934\n",
      "\n",
      "Average Distance = 25.43675438576274\n",
      "\n",
      "F1_shad\n",
      "\n",
      "Total Distance = 541.7978273542909\n",
      "\n",
      "Average Distance = 30.099879297460607\n",
      "\n",
      "F2_shad\n",
      "\n",
      "Total Distance = 721.2159016106498\n",
      "\n",
      "Average Distance = 40.06755008948054\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ini tes banding mfcc per audio langsung dtw\n",
    "\n",
    "# sr = 44100\n",
    "# n_fft = 1024 # 23ms = n_fft / sr\n",
    "# hop_length = 512 # 10ms = hop_length / sr\n",
    "import librosa\n",
    "import noisereduce as nr\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import cosine\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from scipy.signal import butter, lfilter\n",
    "from IPython.display import clear_output\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def remove_silence(y):\n",
    "     # Memisahkan audio menjadi bagian-bagian berdasarkan energi\n",
    "    parts = librosa.effects.split(y, top_db=25, frame_length=1024, hop_length=512)\n",
    "\n",
    "    # Menggabungkan bagian-bagian yang tidak diam\n",
    "    y_non_silent = []\n",
    "    for start, end in parts:\n",
    "        y_non_silent.extend(y[start:end])\n",
    "\n",
    "    # Mengubah list menjadi array numpy\n",
    "    y = np.array(y_non_silent)\n",
    "    return y\n",
    "\n",
    "def preprocessing(audio):\n",
    "    y , sr = librosa.load(audio, sr=44100)\n",
    "    y = librosa.effects.preemphasis(y)\n",
    "    y = y/np.max(np.abs(y))\n",
    "    y = remove_silence(y)\n",
    "    y = nr.reduce_noise(y, sr, prop_decrease=0.8)\n",
    "    return y,sr\n",
    "\n",
    "def extraction(audio):\n",
    "    y , sr = preprocessing(audio)\n",
    "    # y = librosa.effects.preemphasis(y)\n",
    "    mfccs = librosa.feature.mfcc(y=y,\n",
    "                                 sr=sr,\n",
    "                                 n_mfcc=13,\n",
    "                                 window='hamming',\n",
    "                                 win_length=1024,\n",
    "                                 htk=True,\n",
    "                                 hop_length=512,\n",
    "                                 n_fft=1024,\n",
    "                                 norm=None,\n",
    "                                 dct_type=2,\n",
    "                                 n_mels=20)\n",
    "    # mfccs = mfccs[1:]\n",
    "    # mfccs = librosa.util.normalize(mfccs, axis=1 )\n",
    "    # return = librosa.util.normalize(mfccs.T)\n",
    "    return mfccs.T\n",
    "\n",
    "\n",
    "def apply_pca(mfcc_features, n_components):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(mfcc_features)\n",
    "    mfcc_pca = pca.transform(mfcc_features)\n",
    "    return mfcc_pca\n",
    "\n",
    "def calculate_dtw(mfccs1, mfccs2):\n",
    "    distance, _ = fastdtw(mfccs1, mfccs2, dist=cosine)\n",
    "    return distance\n",
    "\n",
    "def main(file_input, audio_name, folder_template, output_file, template_score, max_threshold_score):\n",
    "    audio_input = file_input\n",
    "    templates = os.listdir(folder_template)\n",
    "    # print(f\"len templates = {len(templates)}\")\n",
    "    total_distances = 0\n",
    "\n",
    "    with open(output_file, 'a') as f:\n",
    "        for template in templates:\n",
    "            audio_template = os.path.join(folder_template, template)\n",
    "\n",
    "            mfccs1 = extraction(audio_input)\n",
    "            mfccs2 = np.loadtxt(audio_template,delimiter=',')\n",
    "            # mfccs2 = mfccs2.T\n",
    "            # mfccs2 = mfccs2[1:]\n",
    "            # mfccs2 = mfccs2.T\n",
    "\n",
    "            # mfccs1 = apply_pca(mfccs1,10)\n",
    "            # mfccs2 = apply_pca(mfccs2,10)\n",
    "            # print(f\"mfccs1.shape = {mfccs1.shape}\")\n",
    "            # f.write(f\"mfccs1.shape = {mfccs1.shape}\")\n",
    "            # print(f\"mfccs2.shape = {mfccs2.shape}\")\n",
    "            # f.write(f\"mfccs2.shape = {mfccs2.shape}\")\n",
    "\n",
    "            dtw_distance = calculate_dtw(mfccs1, mfccs2)\n",
    "            # print(f\"dtw_distance = {dtw_distance}\")\n",
    "            # f.write(f\"dtw_distance = {dtw_distance}\")\n",
    "            total_distances += dtw_distance\n",
    "\n",
    "            # result_line = f\"Jarak DTW antara {audio_input} dan {template}: {dtw_distance}\\n\"\n",
    "            # f.write(result_line)\n",
    "\n",
    "        # Tulis hasil total jarak ke file\n",
    "        f.write(audio_name)\n",
    "        print(audio_name)\n",
    "        f.write(f\"\\nTotal Distance = {total_distances}\\n\")\n",
    "        print(f\"\\nTotal Distance = {total_distances}\\n\")\n",
    "\n",
    "        # Hitung rata-rata jarak\n",
    "        average_distance = total_distances / len(templates)\n",
    "        f.write(f\"Average Distance = {average_distance}\\n\")\n",
    "        print(f\"Average Distance = {average_distance}\\n\")\n",
    "        # # Hitung selisih antara rata-rata jarak dengan nilai template\n",
    "        # dif_distance = average_distance - template_score\n",
    "        # f.write(f\"Difference Distance = {dif_distance}\\n\")\n",
    "\n",
    "        # # Hitung skor akhir berdasarkan selisih\n",
    "        # if dif_distance <= 0:\n",
    "        #     final_score = 100\n",
    "        # elif dif_distance >= max_threshold_score:\n",
    "        #     final_score = 0\n",
    "        # else:\n",
    "        #     final_score = int(100 - ((dif_distance / max_threshold_score) * 100))\n",
    "        \n",
    "        # f.write(f\"Final Score = {final_score}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "root = \"../Dataset_MFCC_prem_norm_non_ortho/\"\n",
    "\n",
    "list_template_folders = [\n",
    "    (\"01.Ha'/\"),\n",
    "    (\"02.Kha'/\"),\n",
    "    (\"03.Shad/\"),\n",
    "    (\"04.Dhad/\"),\n",
    "    (\"05.Tha'/\"),\n",
    "    (\"06.Dhza'/\"),\n",
    "    (\"07.'AIn/\"),\n",
    "    (\"08.Ghain/\"),\n",
    "    (\"09.Qaf/\"),\n",
    "    (\"10.Ha^'/\")\n",
    "]\n",
    "# List of audio files and their names\n",
    "list_of_audio_files = [\n",
    "    (\"../Dataset/Testing_Rafi/rafi_shad.wav\", \"rafi_shad\"),\n",
    "    (\"../Dataset/Ridho_mic/Ridho_shad.wav\", \"ridho_shad\"),\n",
    "    (\"../Dataset/Dona_mic/shad_F1_14.wav\", \"F1_shad\"),\n",
    "    (\"../Dataset/Zahrah_mic/shad_F2_14.wav\", \"F2_shad\")\n",
    "]\n",
    "\n",
    "for folder in list_template_folders:\n",
    "    clear_output()\n",
    "    template_folder = os.path.join(root, folder)\n",
    "\n",
    "    output_file = f\"../fix_hasil_testing/non_ortho_prem_norm_testing_shad_template_{folder.strip('/')}.txt\"\n",
    "\n",
    "    template_score = 23.004\n",
    "    max_threshold_score = 5\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "            f.write('')\n",
    "            f.write(f\"Banding {folder.strip('/')} dengan tester\\n\")\n",
    "    print(f\"Processing Folder = {folder.strip('/')}\")\n",
    "    # Iterate over each audio file\n",
    "    for audio_input, audio_name in list_of_audio_files:\n",
    "        main(audio_input,audio_name, template_folder, output_file, template_score, max_threshold_score)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Folder = 10.Ha^'\n",
      "rafi_dhad\n",
      "\n",
      "Total Distance = 330.3983736772654\n",
      "\n",
      "Average Distance = 18.35546520429252\n",
      "\n",
      "ridho_dhad\n",
      "\n",
      "Total Distance = 318.398960947006\n",
      "\n",
      "Average Distance = 17.688831163722554\n",
      "\n",
      "F1_dhad\n",
      "\n",
      "Total Distance = 366.90270258861926\n",
      "\n",
      "Average Distance = 20.383483477145514\n",
      "\n",
      "F2_dhad\n",
      "\n",
      "Total Distance = 253.8695087616106\n",
      "\n",
      "Average Distance = 14.103861597867256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ini tes banding mfcc per audio langsung dtw\n",
    "\n",
    "# sr = 44100\n",
    "# n_fft = 1024 # 23ms = n_fft / sr\n",
    "# hop_length = 512 # 10ms = hop_length / sr\n",
    "import librosa\n",
    "import noisereduce as nr\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import cosine\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from scipy.signal import butter, lfilter\n",
    "from IPython.display import clear_output\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def remove_silence(y):\n",
    "     # Memisahkan audio menjadi bagian-bagian berdasarkan energi\n",
    "    parts = librosa.effects.split(y, top_db=25, frame_length=1024, hop_length=512)\n",
    "\n",
    "    # Menggabungkan bagian-bagian yang tidak diam\n",
    "    y_non_silent = []\n",
    "    for start, end in parts:\n",
    "        y_non_silent.extend(y[start:end])\n",
    "\n",
    "    # Mengubah list menjadi array numpy\n",
    "    y = np.array(y_non_silent)\n",
    "    return y\n",
    "\n",
    "def preprocessing(audio):\n",
    "    y , sr = librosa.load(audio, sr=44100)\n",
    "    y = librosa.effects.preemphasis(y)\n",
    "    y = y/np.max(np.abs(y))\n",
    "    y = remove_silence(y)\n",
    "    y = nr.reduce_noise(y, sr, prop_decrease=0.8)\n",
    "    return y,sr\n",
    "\n",
    "def extraction(audio):\n",
    "    y , sr = preprocessing(audio)\n",
    "    # y = librosa.effects.preemphasis(y)\n",
    "    mfccs = librosa.feature.mfcc(y=y,\n",
    "                                 sr=sr,\n",
    "                                 n_mfcc=13,\n",
    "                                 window='hamming',\n",
    "                                 win_length=1024,\n",
    "                                 htk=True,\n",
    "                                 hop_length=512,\n",
    "                                 n_fft=1024,\n",
    "                                 norm=None,\n",
    "                                 dct_type=2,\n",
    "                                 n_mels=20)\n",
    "    # mfccs = mfccs[1:]\n",
    "    # mfccs = librosa.util.normalize(mfccs, axis=1 )\n",
    "    # return = librosa.util.normalize(mfccs.T)\n",
    "    return mfccs.T\n",
    "\n",
    "\n",
    "def apply_pca(mfcc_features, n_components):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(mfcc_features)\n",
    "    mfcc_pca = pca.transform(mfcc_features)\n",
    "    return mfcc_pca\n",
    "\n",
    "def calculate_dtw(mfccs1, mfccs2):\n",
    "    distance, _ = fastdtw(mfccs1, mfccs2, dist=cosine)\n",
    "    return distance\n",
    "\n",
    "def main(file_input, audio_name, folder_template, output_file, template_score, max_threshold_score):\n",
    "    audio_input = file_input\n",
    "    templates = os.listdir(folder_template)\n",
    "    # print(f\"len templates = {len(templates)}\")\n",
    "    total_distances = 0\n",
    "\n",
    "    with open(output_file, 'a') as f:\n",
    "        for template in templates:\n",
    "            audio_template = os.path.join(folder_template, template)\n",
    "\n",
    "            mfccs1 = extraction(audio_input)\n",
    "            mfccs2 = np.loadtxt(audio_template,delimiter=',')\n",
    "            # mfccs2 = mfccs2.T\n",
    "            # mfccs2 = mfccs2[1:]\n",
    "            # mfccs2 = mfccs2.T\n",
    "\n",
    "            # mfccs1 = apply_pca(mfccs1,10)\n",
    "            # mfccs2 = apply_pca(mfccs2,10)\n",
    "            # print(f\"mfccs1.shape = {mfccs1.shape}\")\n",
    "            # f.write(f\"mfccs1.shape = {mfccs1.shape}\")\n",
    "            # print(f\"mfccs2.shape = {mfccs2.shape}\")\n",
    "            # f.write(f\"mfccs2.shape = {mfccs2.shape}\")\n",
    "\n",
    "            dtw_distance = calculate_dtw(mfccs1, mfccs2)\n",
    "            # print(f\"dtw_distance = {dtw_distance}\")\n",
    "            # f.write(f\"dtw_distance = {dtw_distance}\")\n",
    "            total_distances += dtw_distance\n",
    "\n",
    "            # result_line = f\"Jarak DTW antara {audio_input} dan {template}: {dtw_distance}\\n\"\n",
    "            # f.write(result_line)\n",
    "\n",
    "        # Tulis hasil total jarak ke file\n",
    "        f.write(audio_name)\n",
    "        print(audio_name)\n",
    "        f.write(f\"\\nTotal Distance = {total_distances}\\n\")\n",
    "        print(f\"\\nTotal Distance = {total_distances}\\n\")\n",
    "\n",
    "        # Hitung rata-rata jarak\n",
    "        average_distance = total_distances / len(templates)\n",
    "        f.write(f\"Average Distance = {average_distance}\\n\")\n",
    "        print(f\"Average Distance = {average_distance}\\n\")\n",
    "        # # Hitung selisih antara rata-rata jarak dengan nilai template\n",
    "        # dif_distance = average_distance - template_score\n",
    "        # f.write(f\"Difference Distance = {dif_distance}\\n\")\n",
    "\n",
    "        # # Hitung skor akhir berdasarkan selisih\n",
    "        # if dif_distance <= 0:\n",
    "        #     final_score = 100\n",
    "        # elif dif_distance >= max_threshold_score:\n",
    "        #     final_score = 0\n",
    "        # else:\n",
    "        #     final_score = int(100 - ((dif_distance / max_threshold_score) * 100))\n",
    "        \n",
    "        # f.write(f\"Final Score = {final_score}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "root = \"../Dataset_MFCC_prem_norm_non_ortho/\"\n",
    "\n",
    "list_template_folders = [\n",
    "    (\"01.Ha'/\"),\n",
    "    (\"02.Kha'/\"),\n",
    "    (\"03.Shad/\"),\n",
    "    (\"04.Dhad/\"),\n",
    "    (\"05.Tha'/\"),\n",
    "    (\"06.Dhza'/\"),\n",
    "    (\"07.'AIn/\"),\n",
    "    (\"08.Ghain/\"),\n",
    "    (\"09.Qaf/\"),\n",
    "    (\"10.Ha^'/\")\n",
    "]\n",
    "# List of audio files and their names\n",
    "list_of_audio_files = [\n",
    "    (\"../Dataset/Testing_Rafi/rafi_dhad.wav\", \"rafi_dhad\"),\n",
    "    (\"../Dataset/Ridho_mic/Ridho_dhad.wav\", \"ridho_dhad\"),\n",
    "    (\"../Dataset/Dona_mic/dhad_F1_14.wav\", \"F1_dhad\"),\n",
    "    (\"../Dataset/Zahrah_mic/dhad_F2_14.wav\", \"F2_dhad\")\n",
    "]\n",
    "\n",
    "for folder in list_template_folders:\n",
    "    clear_output()\n",
    "    template_folder = os.path.join(root, folder)\n",
    "\n",
    "    output_file = f\"../fix_hasil_testing/non_ortho_prem_norm_testing_dhad_template_{folder.strip('/')}.txt\"\n",
    "\n",
    "    template_score = 23.004\n",
    "    max_threshold_score = 5\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "            f.write('')\n",
    "            f.write(f\"Banding {folder.strip('/')} dengan tester\\n\")\n",
    "    print(f\"Processing Folder = {folder.strip('/')}\")\n",
    "    # Iterate over each audio file\n",
    "    for audio_input, audio_name in list_of_audio_files:\n",
    "        main(audio_input,audio_name, template_folder, output_file, template_score, max_threshold_score)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Folder = 10.Ha^'\n",
      "rafi_tha'\n",
      "\n",
      "Total Distance = 264.2266583929609\n",
      "\n",
      "Average Distance = 14.67925879960894\n",
      "\n",
      "ridho_tha'\n",
      "\n",
      "Total Distance = 321.6671801352177\n",
      "\n",
      "Average Distance = 17.87039889640098\n",
      "\n",
      "F1_tha'\n",
      "\n",
      "Total Distance = 413.8758160321844\n",
      "\n",
      "Average Distance = 22.99310089067691\n",
      "\n",
      "F2_tha'\n",
      "\n",
      "Total Distance = 279.1000952658345\n",
      "\n",
      "Average Distance = 15.505560848101917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ini tes banding mfcc per audio langsung dtw\n",
    "\n",
    "# sr = 44100\n",
    "# n_fft = 1024 # 23ms = n_fft / sr\n",
    "# hop_length = 512 # 10ms = hop_length / sr\n",
    "import librosa\n",
    "import noisereduce as nr\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import cosine\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from scipy.signal import butter, lfilter\n",
    "from IPython.display import clear_output\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def remove_silence(y):\n",
    "     # Memisahkan audio menjadi bagian-bagian berdasarkan energi\n",
    "    parts = librosa.effects.split(y, top_db=25, frame_length=1024, hop_length=512)\n",
    "\n",
    "    # Menggabungkan bagian-bagian yang tidak diam\n",
    "    y_non_silent = []\n",
    "    for start, end in parts:\n",
    "        y_non_silent.extend(y[start:end])\n",
    "\n",
    "    # Mengubah list menjadi array numpy\n",
    "    y = np.array(y_non_silent)\n",
    "    return y\n",
    "\n",
    "def preprocessing(audio):\n",
    "    y , sr = librosa.load(audio, sr=44100)\n",
    "    y = librosa.effects.preemphasis(y)\n",
    "    y = y/np.max(np.abs(y))\n",
    "    y = remove_silence(y)\n",
    "    y = nr.reduce_noise(y, sr, prop_decrease=0.8)\n",
    "    return y,sr\n",
    "\n",
    "def extraction(audio):\n",
    "    y , sr = preprocessing(audio)\n",
    "    # y = librosa.effects.preemphasis(y)\n",
    "    mfccs = librosa.feature.mfcc(y=y,\n",
    "                                 sr=sr,\n",
    "                                 n_mfcc=13,\n",
    "                                 window='hamming',\n",
    "                                 win_length=1024,\n",
    "                                 htk=True,\n",
    "                                 hop_length=512,\n",
    "                                 n_fft=1024,\n",
    "                                 norm=None,\n",
    "                                 dct_type=2,\n",
    "                                 n_mels=20)\n",
    "    # mfccs = mfccs[1:]\n",
    "    # mfccs = librosa.util.normalize(mfccs, axis=1 )\n",
    "    # return = librosa.util.normalize(mfccs.T)\n",
    "    return mfccs.T\n",
    "\n",
    "\n",
    "def apply_pca(mfcc_features, n_components):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(mfcc_features)\n",
    "    mfcc_pca = pca.transform(mfcc_features)\n",
    "    return mfcc_pca\n",
    "\n",
    "def calculate_dtw(mfccs1, mfccs2):\n",
    "    distance, _ = fastdtw(mfccs1, mfccs2, dist=cosine)\n",
    "    return distance\n",
    "\n",
    "def main(file_input, audio_name, folder_template, output_file, template_score, max_threshold_score):\n",
    "    audio_input = file_input\n",
    "    templates = os.listdir(folder_template)\n",
    "    # print(f\"len templates = {len(templates)}\")\n",
    "    total_distances = 0\n",
    "\n",
    "    with open(output_file, 'a') as f:\n",
    "        for template in templates:\n",
    "            audio_template = os.path.join(folder_template, template)\n",
    "\n",
    "            mfccs1 = extraction(audio_input)\n",
    "            mfccs2 = np.loadtxt(audio_template,delimiter=',')\n",
    "            # mfccs2 = mfccs2.T\n",
    "            # mfccs2 = mfccs2[1:]\n",
    "            # mfccs2 = mfccs2.T\n",
    "\n",
    "            # mfccs1 = apply_pca(mfccs1,10)\n",
    "            # mfccs2 = apply_pca(mfccs2,10)\n",
    "            # print(f\"mfccs1.shape = {mfccs1.shape}\")\n",
    "            # f.write(f\"mfccs1.shape = {mfccs1.shape}\")\n",
    "            # print(f\"mfccs2.shape = {mfccs2.shape}\")\n",
    "            # f.write(f\"mfccs2.shape = {mfccs2.shape}\")\n",
    "\n",
    "            dtw_distance = calculate_dtw(mfccs1, mfccs2)\n",
    "            # print(f\"dtw_distance = {dtw_distance}\")\n",
    "            # f.write(f\"dtw_distance = {dtw_distance}\")\n",
    "            total_distances += dtw_distance\n",
    "\n",
    "            # result_line = f\"Jarak DTW antara {audio_input} dan {template}: {dtw_distance}\\n\"\n",
    "            # f.write(result_line)\n",
    "\n",
    "        # Tulis hasil total jarak ke file\n",
    "        f.write(audio_name)\n",
    "        print(audio_name)\n",
    "        f.write(f\"\\nTotal Distance = {total_distances}\\n\")\n",
    "        print(f\"\\nTotal Distance = {total_distances}\\n\")\n",
    "\n",
    "        # Hitung rata-rata jarak\n",
    "        average_distance = total_distances / len(templates)\n",
    "        f.write(f\"Average Distance = {average_distance}\\n\")\n",
    "        print(f\"Average Distance = {average_distance}\\n\")\n",
    "        # # Hitung selisih antara rata-rata jarak dengan nilai template\n",
    "        # dif_distance = average_distance - template_score\n",
    "        # f.write(f\"Difference Distance = {dif_distance}\\n\")\n",
    "\n",
    "        # # Hitung skor akhir berdasarkan selisih\n",
    "        # if dif_distance <= 0:\n",
    "        #     final_score = 100\n",
    "        # elif dif_distance >= max_threshold_score:\n",
    "        #     final_score = 0\n",
    "        # else:\n",
    "        #     final_score = int(100 - ((dif_distance / max_threshold_score) * 100))\n",
    "        \n",
    "        # f.write(f\"Final Score = {final_score}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "root = \"../Dataset_MFCC_prem_norm_non_ortho/\"\n",
    "\n",
    "list_template_folders = [\n",
    "    (\"01.Ha'/\"),\n",
    "    (\"02.Kha'/\"),\n",
    "    (\"03.Shad/\"),\n",
    "    (\"04.Dhad/\"),\n",
    "    (\"05.Tha'/\"),\n",
    "    (\"06.Dhza'/\"),\n",
    "    (\"07.'AIn/\"),\n",
    "    (\"08.Ghain/\"),\n",
    "    (\"09.Qaf/\"),\n",
    "    (\"10.Ha^'/\")\n",
    "]\n",
    "# List of audio files and their names\n",
    "list_of_audio_files = [\n",
    "    (\"../Dataset/Testing_Rafi/rafi_tha'.wav\", \"rafi_tha'\"),\n",
    "    (\"../Dataset/Ridho_mic/Ridho_tha'.wav\", \"ridho_tha'\"),\n",
    "    (\"../Dataset/Dona_mic/tha'_F1_14.wav\", \"F1_tha'\"),\n",
    "    (\"../Dataset/Zahrah_mic/tha'_F2_14.wav\", \"F2_tha'\")\n",
    "]\n",
    "\n",
    "for folder in list_template_folders:\n",
    "    clear_output()\n",
    "    template_folder = os.path.join(root, folder)\n",
    "\n",
    "    output_file = f\"../fix_hasil_testing/non_ortho_prem_norm_testing_tha'_template_{folder.strip('/')}.txt\"\n",
    "\n",
    "    template_score = 23.004\n",
    "    max_threshold_score = 5\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "            f.write('')\n",
    "            f.write(f\"Banding {folder.strip('/')} dengan tester\\n\")\n",
    "    print(f\"Processing Folder = {folder.strip('/')}\")\n",
    "    # Iterate over each audio file\n",
    "    for audio_input, audio_name in list_of_audio_files:\n",
    "        main(audio_input,audio_name, template_folder, output_file, template_score, max_threshold_score)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Folder = 10.Ha^'\n",
      "rafi_dhza'\n",
      "\n",
      "Total Distance = 363.94173330842995\n",
      "\n",
      "Average Distance = 20.218985183801664\n",
      "\n",
      "ridho_dhza'\n",
      "\n",
      "Total Distance = 352.2032064107973\n",
      "\n",
      "Average Distance = 19.56684480059985\n",
      "\n",
      "F1_dhza'\n",
      "\n",
      "Total Distance = 512.1486680257626\n",
      "\n",
      "Average Distance = 28.452703779209035\n",
      "\n",
      "F2_dhza'\n",
      "\n",
      "Total Distance = 278.4448606093621\n",
      "\n",
      "Average Distance = 15.469158922742338\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ini tes banding mfcc per audio langsung dtw\n",
    "\n",
    "# sr = 44100\n",
    "# n_fft = 1024 # 23ms = n_fft / sr\n",
    "# hop_length = 512 # 10ms = hop_length / sr\n",
    "import librosa\n",
    "import noisereduce as nr\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import cosine\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from scipy.signal import butter, lfilter\n",
    "from IPython.display import clear_output\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def remove_silence(y):\n",
    "     # Memisahkan audio menjadi bagian-bagian berdasarkan energi\n",
    "    parts = librosa.effects.split(y, top_db=25, frame_length=1024, hop_length=512)\n",
    "\n",
    "    # Menggabungkan bagian-bagian yang tidak diam\n",
    "    y_non_silent = []\n",
    "    for start, end in parts:\n",
    "        y_non_silent.extend(y[start:end])\n",
    "\n",
    "    # Mengubah list menjadi array numpy\n",
    "    y = np.array(y_non_silent)\n",
    "    return y\n",
    "\n",
    "def preprocessing(audio):\n",
    "    y , sr = librosa.load(audio, sr=44100)\n",
    "    y = librosa.effects.preemphasis(y)\n",
    "    y = y/np.max(np.abs(y))\n",
    "    y = remove_silence(y)\n",
    "    y = nr.reduce_noise(y, sr, prop_decrease=0.8)\n",
    "    return y,sr\n",
    "\n",
    "def extraction(audio):\n",
    "    y , sr = preprocessing(audio)\n",
    "    # y = librosa.effects.preemphasis(y)\n",
    "    mfccs = librosa.feature.mfcc(y=y,\n",
    "                                 sr=sr,\n",
    "                                 n_mfcc=13,\n",
    "                                 window='hamming',\n",
    "                                 win_length=1024,\n",
    "                                 htk=True,\n",
    "                                 hop_length=512,\n",
    "                                 n_fft=1024,\n",
    "                                 norm=None,\n",
    "                                 dct_type=2,\n",
    "                                 n_mels=20)\n",
    "    # mfccs = mfccs[1:]\n",
    "    # mfccs = librosa.util.normalize(mfccs, axis=1 )\n",
    "    # return = librosa.util.normalize(mfccs.T)\n",
    "    return mfccs.T\n",
    "\n",
    "\n",
    "def apply_pca(mfcc_features, n_components):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(mfcc_features)\n",
    "    mfcc_pca = pca.transform(mfcc_features)\n",
    "    return mfcc_pca\n",
    "\n",
    "def calculate_dtw(mfccs1, mfccs2):\n",
    "    distance, _ = fastdtw(mfccs1, mfccs2, dist=cosine)\n",
    "    return distance\n",
    "\n",
    "def main(file_input, audio_name, folder_template, output_file, template_score, max_threshold_score):\n",
    "    audio_input = file_input\n",
    "    templates = os.listdir(folder_template)\n",
    "    # print(f\"len templates = {len(templates)}\")\n",
    "    total_distances = 0\n",
    "\n",
    "    with open(output_file, 'a') as f:\n",
    "        for template in templates:\n",
    "            audio_template = os.path.join(folder_template, template)\n",
    "\n",
    "            mfccs1 = extraction(audio_input)\n",
    "            mfccs2 = np.loadtxt(audio_template,delimiter=',')\n",
    "            # mfccs2 = mfccs2.T\n",
    "            # mfccs2 = mfccs2[1:]\n",
    "            # mfccs2 = mfccs2.T\n",
    "\n",
    "            # mfccs1 = apply_pca(mfccs1,10)\n",
    "            # mfccs2 = apply_pca(mfccs2,10)\n",
    "            # print(f\"mfccs1.shape = {mfccs1.shape}\")\n",
    "            # f.write(f\"mfccs1.shape = {mfccs1.shape}\")\n",
    "            # print(f\"mfccs2.shape = {mfccs2.shape}\")\n",
    "            # f.write(f\"mfccs2.shape = {mfccs2.shape}\")\n",
    "\n",
    "            dtw_distance = calculate_dtw(mfccs1, mfccs2)\n",
    "            # print(f\"dtw_distance = {dtw_distance}\")\n",
    "            # f.write(f\"dtw_distance = {dtw_distance}\")\n",
    "            total_distances += dtw_distance\n",
    "\n",
    "            # result_line = f\"Jarak DTW antara {audio_input} dan {template}: {dtw_distance}\\n\"\n",
    "            # f.write(result_line)\n",
    "\n",
    "        # Tulis hasil total jarak ke file\n",
    "        f.write(audio_name)\n",
    "        print(audio_name)\n",
    "        f.write(f\"\\nTotal Distance = {total_distances}\\n\")\n",
    "        print(f\"\\nTotal Distance = {total_distances}\\n\")\n",
    "\n",
    "        # Hitung rata-rata jarak\n",
    "        average_distance = total_distances / len(templates)\n",
    "        f.write(f\"Average Distance = {average_distance}\\n\")\n",
    "        print(f\"Average Distance = {average_distance}\\n\")\n",
    "        # # Hitung selisih antara rata-rata jarak dengan nilai template\n",
    "        # dif_distance = average_distance - template_score\n",
    "        # f.write(f\"Difference Distance = {dif_distance}\\n\")\n",
    "\n",
    "        # # Hitung skor akhir berdasarkan selisih\n",
    "        # if dif_distance <= 0:\n",
    "        #     final_score = 100\n",
    "        # elif dif_distance >= max_threshold_score:\n",
    "        #     final_score = 0\n",
    "        # else:\n",
    "        #     final_score = int(100 - ((dif_distance / max_threshold_score) * 100))\n",
    "        \n",
    "        # f.write(f\"Final Score = {final_score}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "root = \"../Dataset_MFCC_prem_norm_non_ortho/\"\n",
    "\n",
    "list_template_folders = [\n",
    "    (\"01.Ha'/\"),\n",
    "    (\"02.Kha'/\"),\n",
    "    (\"03.Shad/\"),\n",
    "    (\"04.Dhad/\"),\n",
    "    (\"05.Tha'/\"),\n",
    "    (\"06.Dhza'/\"),\n",
    "    (\"07.'AIn/\"),\n",
    "    (\"08.Ghain/\"),\n",
    "    (\"09.Qaf/\"),\n",
    "    (\"10.Ha^'/\")\n",
    "]\n",
    "# List of audio files and their names\n",
    "list_of_audio_files = [\n",
    "    (\"../Dataset/Testing_Rafi/rafi_dhza'.wav\", \"rafi_dhza'\"),\n",
    "    (\"../Dataset/Ridho_mic/Ridho_dhza'.wav\", \"ridho_dhza'\"),\n",
    "    (\"../Dataset/Dona_mic/dhza'_F1_14.wav\", \"F1_dhza'\"),\n",
    "    (\"../Dataset/Zahrah_mic/dhza'_F2_14.wav\", \"F2_dhza'\")\n",
    "]\n",
    "\n",
    "for folder in list_template_folders:\n",
    "    clear_output()\n",
    "    template_folder = os.path.join(root, folder)\n",
    "\n",
    "    output_file = f\"../fix_hasil_testing/non_ortho_prem_norm_testing_dhza'_template_{folder.strip('/')}.txt\"\n",
    "\n",
    "    template_score = 23.004\n",
    "    max_threshold_score = 5\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "            f.write('')\n",
    "            f.write(f\"Banding {folder.strip('/')} dengan tester\\n\")\n",
    "    print(f\"Processing Folder = {folder.strip('/')}\")\n",
    "    # Iterate over each audio file\n",
    "    for audio_input, audio_name in list_of_audio_files:\n",
    "        main(audio_input,audio_name, template_folder, output_file, template_score, max_threshold_score)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Folder = 10.Ha^'\n",
      "rafi_'ain\n",
      "\n",
      "Total Distance = 309.93059084993496\n",
      "\n",
      "Average Distance = 17.21836615832972\n",
      "\n",
      "ridho_'ain\n",
      "\n",
      "Total Distance = 318.12970288210204\n",
      "\n",
      "Average Distance = 17.673872382339002\n",
      "\n",
      "F1_'ain\n",
      "\n",
      "Total Distance = 417.31655985735694\n",
      "\n",
      "Average Distance = 23.18425332540872\n",
      "\n",
      "F2_'ain\n",
      "\n",
      "Total Distance = 316.8026098284907\n",
      "\n",
      "Average Distance = 17.600144990471705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ini tes banding mfcc per audio langsung dtw\n",
    "\n",
    "# sr = 44100\n",
    "# n_fft = 1024 # 23ms = n_fft / sr\n",
    "# hop_length = 512 # 10ms = hop_length / sr\n",
    "import librosa\n",
    "import noisereduce as nr\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import cosine\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from scipy.signal import butter, lfilter\n",
    "from IPython.display import clear_output\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def remove_silence(y):\n",
    "     # Memisahkan audio menjadi bagian-bagian berdasarkan energi\n",
    "    parts = librosa.effects.split(y, top_db=25, frame_length=1024, hop_length=512)\n",
    "\n",
    "    # Menggabungkan bagian-bagian yang tidak diam\n",
    "    y_non_silent = []\n",
    "    for start, end in parts:\n",
    "        y_non_silent.extend(y[start:end])\n",
    "\n",
    "    # Mengubah list menjadi array numpy\n",
    "    y = np.array(y_non_silent)\n",
    "    return y\n",
    "\n",
    "def preprocessing(audio):\n",
    "    y , sr = librosa.load(audio, sr=44100)\n",
    "    y = librosa.effects.preemphasis(y)\n",
    "    y = y/np.max(np.abs(y))\n",
    "    y = remove_silence(y)\n",
    "    y = nr.reduce_noise(y, sr, prop_decrease=0.8)\n",
    "    return y,sr\n",
    "\n",
    "def extraction(audio):\n",
    "    y , sr = preprocessing(audio)\n",
    "    # y = librosa.effects.preemphasis(y)\n",
    "    mfccs = librosa.feature.mfcc(y=y,\n",
    "                                 sr=sr,\n",
    "                                 n_mfcc=13,\n",
    "                                 window='hamming',\n",
    "                                 win_length=1024,\n",
    "                                 htk=True,\n",
    "                                 hop_length=512,\n",
    "                                 n_fft=1024,\n",
    "                                 norm=None,\n",
    "                                 dct_type=2,\n",
    "                                 n_mels=20)\n",
    "    # mfccs = mfccs[1:]\n",
    "    # mfccs = librosa.util.normalize(mfccs, axis=1 )\n",
    "    # return = librosa.util.normalize(mfccs.T)\n",
    "    return mfccs.T\n",
    "\n",
    "\n",
    "def apply_pca(mfcc_features, n_components):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(mfcc_features)\n",
    "    mfcc_pca = pca.transform(mfcc_features)\n",
    "    return mfcc_pca\n",
    "\n",
    "def calculate_dtw(mfccs1, mfccs2):\n",
    "    distance, _ = fastdtw(mfccs1, mfccs2, dist=cosine)\n",
    "    return distance\n",
    "\n",
    "def main(file_input, audio_name, folder_template, output_file, template_score, max_threshold_score):\n",
    "    audio_input = file_input\n",
    "    templates = os.listdir(folder_template)\n",
    "    # print(f\"len templates = {len(templates)}\")\n",
    "    total_distances = 0\n",
    "\n",
    "    with open(output_file, 'a') as f:\n",
    "        for template in templates:\n",
    "            audio_template = os.path.join(folder_template, template)\n",
    "\n",
    "            mfccs1 = extraction(audio_input)\n",
    "            mfccs2 = np.loadtxt(audio_template,delimiter=',')\n",
    "            # mfccs2 = mfccs2.T\n",
    "            # mfccs2 = mfccs2[1:]\n",
    "            # mfccs2 = mfccs2.T\n",
    "\n",
    "            # mfccs1 = apply_pca(mfccs1,10)\n",
    "            # mfccs2 = apply_pca(mfccs2,10)\n",
    "            # print(f\"mfccs1.shape = {mfccs1.shape}\")\n",
    "            # f.write(f\"mfccs1.shape = {mfccs1.shape}\")\n",
    "            # print(f\"mfccs2.shape = {mfccs2.shape}\")\n",
    "            # f.write(f\"mfccs2.shape = {mfccs2.shape}\")\n",
    "\n",
    "            dtw_distance = calculate_dtw(mfccs1, mfccs2)\n",
    "            # print(f\"dtw_distance = {dtw_distance}\")\n",
    "            # f.write(f\"dtw_distance = {dtw_distance}\")\n",
    "            total_distances += dtw_distance\n",
    "\n",
    "            # result_line = f\"Jarak DTW antara {audio_input} dan {template}: {dtw_distance}\\n\"\n",
    "            # f.write(result_line)\n",
    "\n",
    "        # Tulis hasil total jarak ke file\n",
    "        f.write(audio_name)\n",
    "        print(audio_name)\n",
    "        f.write(f\"\\nTotal Distance = {total_distances}\\n\")\n",
    "        print(f\"\\nTotal Distance = {total_distances}\\n\")\n",
    "\n",
    "        # Hitung rata-rata jarak\n",
    "        average_distance = total_distances / len(templates)\n",
    "        f.write(f\"Average Distance = {average_distance}\\n\")\n",
    "        print(f\"Average Distance = {average_distance}\\n\")\n",
    "        # # Hitung selisih antara rata-rata jarak dengan nilai template\n",
    "        # dif_distance = average_distance - template_score\n",
    "        # f.write(f\"Difference Distance = {dif_distance}\\n\")\n",
    "\n",
    "        # # Hitung skor akhir berdasarkan selisih\n",
    "        # if dif_distance <= 0:\n",
    "        #     final_score = 100\n",
    "        # elif dif_distance >= max_threshold_score:\n",
    "        #     final_score = 0\n",
    "        # else:\n",
    "        #     final_score = int(100 - ((dif_distance / max_threshold_score) * 100))\n",
    "        \n",
    "        # f.write(f\"Final Score = {final_score}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "root = \"../Dataset_MFCC_prem_norm_non_ortho/\"\n",
    "\n",
    "list_template_folders = [\n",
    "    (\"01.Ha'/\"),\n",
    "    (\"02.Kha'/\"),\n",
    "    (\"03.Shad/\"),\n",
    "    (\"04.Dhad/\"),\n",
    "    (\"05.Tha'/\"),\n",
    "    (\"06.Dhza'/\"),\n",
    "    (\"07.'AIn/\"),\n",
    "    (\"08.Ghain/\"),\n",
    "    (\"09.Qaf/\"),\n",
    "    (\"10.Ha^'/\")\n",
    "]\n",
    "# List of audio files and their names\n",
    "list_of_audio_files = [\n",
    "    (\"../Dataset/Testing_Rafi/rafi_'ain.wav\", \"rafi_'ain\"),\n",
    "    (\"../Dataset/Ridho_mic/Ridho_'ain.wav\", \"ridho_'ain\"),\n",
    "    (\"../Dataset/Dona_mic/'ain_F1_14.wav\", \"F1_'ain\"),\n",
    "    (\"../Dataset/Zahrah_mic/'ain_F2_14.wav\", \"F2_'ain\")\n",
    "]\n",
    "\n",
    "for folder in list_template_folders:\n",
    "    clear_output()\n",
    "    template_folder = os.path.join(root, folder)\n",
    "\n",
    "    output_file = f\"../fix_hasil_testing/non_ortho_prem_norm_testing_'ain_template_{folder.strip('/')}.txt\"\n",
    "\n",
    "    template_score = 23.004\n",
    "    max_threshold_score = 5\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "            f.write('')\n",
    "            f.write(f\"Banding {folder.strip('/')} dengan tester\\n\")\n",
    "    print(f\"Processing Folder = {folder.strip('/')}\")\n",
    "    # Iterate over each audio file\n",
    "    for audio_input, audio_name in list_of_audio_files:\n",
    "        main(audio_input,audio_name, template_folder, output_file, template_score, max_threshold_score)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Folder = 10.Ha^'\n",
      "rafi_Ghain\n",
      "\n",
      "Total Distance = 334.0756745921165\n",
      "\n",
      "Average Distance = 18.55975969956203\n",
      "\n",
      "ridho_Ghain\n",
      "\n",
      "Total Distance = 316.7619799799113\n",
      "\n",
      "Average Distance = 17.59788777666174\n",
      "\n",
      "F1_Ghain\n",
      "\n",
      "Total Distance = 471.2288568352683\n",
      "\n",
      "Average Distance = 26.179380935292684\n",
      "\n",
      "F2_Ghain\n",
      "\n",
      "Total Distance = 328.94231066620307\n",
      "\n",
      "Average Distance = 18.27457281478906\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ini tes banding mfcc per audio langsung dtw\n",
    "\n",
    "# sr = 44100\n",
    "# n_fft = 1024 # 23ms = n_fft / sr\n",
    "# hop_length = 512 # 10ms = hop_length / sr\n",
    "import librosa\n",
    "import noisereduce as nr\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import cosine\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from scipy.signal import butter, lfilter\n",
    "from IPython.display import clear_output\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def remove_silence(y):\n",
    "     # Memisahkan audio menjadi bagian-bagian berdasarkan energi\n",
    "    parts = librosa.effects.split(y, top_db=25, frame_length=1024, hop_length=512)\n",
    "\n",
    "    # Menggabungkan bagian-bagian yang tidak diam\n",
    "    y_non_silent = []\n",
    "    for start, end in parts:\n",
    "        y_non_silent.extend(y[start:end])\n",
    "\n",
    "    # Mengubah list menjadi array numpy\n",
    "    y = np.array(y_non_silent)\n",
    "    return y\n",
    "\n",
    "def preprocessing(audio):\n",
    "    y , sr = librosa.load(audio, sr=44100)\n",
    "    y = librosa.effects.preemphasis(y)\n",
    "    y = y/np.max(np.abs(y))\n",
    "    y = remove_silence(y)\n",
    "    y = nr.reduce_noise(y, sr, prop_decrease=0.8)\n",
    "    return y,sr\n",
    "\n",
    "def extraction(audio):\n",
    "    y , sr = preprocessing(audio)\n",
    "    # y = librosa.effects.preemphasis(y)\n",
    "    mfccs = librosa.feature.mfcc(y=y,\n",
    "                                 sr=sr,\n",
    "                                 n_mfcc=13,\n",
    "                                 window='hamming',\n",
    "                                 win_length=1024,\n",
    "                                 htk=True,\n",
    "                                 hop_length=512,\n",
    "                                 n_fft=1024,\n",
    "                                 norm=None,\n",
    "                                 dct_type=2,\n",
    "                                 n_mels=20)\n",
    "    # mfccs = mfccs[1:]\n",
    "    # mfccs = librosa.util.normalize(mfccs, axis=1 )\n",
    "    # return = librosa.util.normalize(mfccs.T)\n",
    "    return mfccs.T\n",
    "\n",
    "\n",
    "def apply_pca(mfcc_features, n_components):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(mfcc_features)\n",
    "    mfcc_pca = pca.transform(mfcc_features)\n",
    "    return mfcc_pca\n",
    "\n",
    "def calculate_dtw(mfccs1, mfccs2):\n",
    "    distance, _ = fastdtw(mfccs1, mfccs2, dist=cosine)\n",
    "    return distance\n",
    "\n",
    "def main(file_input, audio_name, folder_template, output_file, template_score, max_threshold_score):\n",
    "    audio_input = file_input\n",
    "    templates = os.listdir(folder_template)\n",
    "    # print(f\"len templates = {len(templates)}\")\n",
    "    total_distances = 0\n",
    "\n",
    "    with open(output_file, 'a') as f:\n",
    "        for template in templates:\n",
    "            audio_template = os.path.join(folder_template, template)\n",
    "\n",
    "            mfccs1 = extraction(audio_input)\n",
    "            mfccs2 = np.loadtxt(audio_template,delimiter=',')\n",
    "            # mfccs2 = mfccs2.T\n",
    "            # mfccs2 = mfccs2[1:]\n",
    "            # mfccs2 = mfccs2.T\n",
    "\n",
    "            # mfccs1 = apply_pca(mfccs1,10)\n",
    "            # mfccs2 = apply_pca(mfccs2,10)\n",
    "            # print(f\"mfccs1.shape = {mfccs1.shape}\")\n",
    "            # f.write(f\"mfccs1.shape = {mfccs1.shape}\")\n",
    "            # print(f\"mfccs2.shape = {mfccs2.shape}\")\n",
    "            # f.write(f\"mfccs2.shape = {mfccs2.shape}\")\n",
    "\n",
    "            dtw_distance = calculate_dtw(mfccs1, mfccs2)\n",
    "            # print(f\"dtw_distance = {dtw_distance}\")\n",
    "            # f.write(f\"dtw_distance = {dtw_distance}\")\n",
    "            total_distances += dtw_distance\n",
    "\n",
    "            # result_line = f\"Jarak DTW antara {audio_input} dan {template}: {dtw_distance}\\n\"\n",
    "            # f.write(result_line)\n",
    "\n",
    "        # Tulis hasil total jarak ke file\n",
    "        f.write(audio_name)\n",
    "        print(audio_name)\n",
    "        f.write(f\"\\nTotal Distance = {total_distances}\\n\")\n",
    "        print(f\"\\nTotal Distance = {total_distances}\\n\")\n",
    "\n",
    "        # Hitung rata-rata jarak\n",
    "        average_distance = total_distances / len(templates)\n",
    "        f.write(f\"Average Distance = {average_distance}\\n\")\n",
    "        print(f\"Average Distance = {average_distance}\\n\")\n",
    "        # # Hitung selisih antara rata-rata jarak dengan nilai template\n",
    "        # dif_distance = average_distance - template_score\n",
    "        # f.write(f\"Difference Distance = {dif_distance}\\n\")\n",
    "\n",
    "        # # Hitung skor akhir berdasarkan selisih\n",
    "        # if dif_distance <= 0:\n",
    "        #     final_score = 100\n",
    "        # elif dif_distance >= max_threshold_score:\n",
    "        #     final_score = 0\n",
    "        # else:\n",
    "        #     final_score = int(100 - ((dif_distance / max_threshold_score) * 100))\n",
    "        \n",
    "        # f.write(f\"Final Score = {final_score}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "root = \"../Dataset_MFCC_prem_norm_non_ortho/\"\n",
    "\n",
    "list_template_folders = [\n",
    "    (\"01.Ha'/\"),\n",
    "    (\"02.Kha'/\"),\n",
    "    (\"03.Shad/\"),\n",
    "    (\"04.Dhad/\"),\n",
    "    (\"05.Tha'/\"),\n",
    "    (\"06.Dhza'/\"),\n",
    "    (\"07.'AIn/\"),\n",
    "    (\"08.Ghain/\"),\n",
    "    (\"09.Qaf/\"),\n",
    "    (\"10.Ha^'/\")\n",
    "]\n",
    "# List of audio files and their names\n",
    "list_of_audio_files = [\n",
    "    (\"../Dataset/Testing_Rafi/rafi_Ghain.wav\", \"rafi_Ghain\"),\n",
    "    (\"../Dataset/Ridho_mic/Ridho_Ghain.wav\", \"ridho_Ghain\"),\n",
    "    (\"../Dataset/Dona_mic/Ghain_F1_14.wav\", \"F1_Ghain\"),\n",
    "    (\"../Dataset/Zahrah_mic/Ghain_F2_14.wav\", \"F2_Ghain\")\n",
    "]\n",
    "\n",
    "for folder in list_template_folders:\n",
    "    clear_output()\n",
    "    template_folder = os.path.join(root, folder)\n",
    "\n",
    "    output_file = f\"../fix_hasil_testing/non_ortho_prem_norm_testing_Ghain_template_{folder.strip('/')}.txt\"\n",
    "\n",
    "    template_score = 23.004\n",
    "    max_threshold_score = 5\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "            f.write('')\n",
    "            f.write(f\"Banding {folder.strip('/')} dengan tester\\n\")\n",
    "    print(f\"Processing Folder = {folder.strip('/')}\")\n",
    "    # Iterate over each audio file\n",
    "    for audio_input, audio_name in list_of_audio_files:\n",
    "        main(audio_input,audio_name, template_folder, output_file, template_score, max_threshold_score)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Folder = 10.Ha^'\n",
      "rafi_qaf\n",
      "\n",
      "Total Distance = 293.883076583415\n",
      "\n",
      "Average Distance = 16.3268375879675\n",
      "\n",
      "ridho_qaf\n",
      "\n",
      "Total Distance = 330.3730504702101\n",
      "\n",
      "Average Distance = 18.35405835945612\n",
      "\n",
      "F1_qaf\n",
      "\n",
      "Total Distance = 415.3130290216632\n",
      "\n",
      "Average Distance = 23.07294605675907\n",
      "\n",
      "F2_qaf\n",
      "\n",
      "Total Distance = 301.8847789716288\n",
      "\n",
      "Average Distance = 16.771376609534933\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ini tes banding mfcc per audio langsung dtw\n",
    "\n",
    "# sr = 44100\n",
    "# n_fft = 1024 # 23ms = n_fft / sr\n",
    "# hop_length = 512 # 10ms = hop_length / sr\n",
    "import librosa\n",
    "import noisereduce as nr\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import cosine\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from scipy.signal import butter, lfilter\n",
    "from IPython.display import clear_output\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def remove_silence(y):\n",
    "     # Memisahkan audio menjadi bagian-bagian berdasarkan energi\n",
    "    parts = librosa.effects.split(y, top_db=25, frame_length=1024, hop_length=512)\n",
    "\n",
    "    # Menggabungkan bagian-bagian yang tidak diam\n",
    "    y_non_silent = []\n",
    "    for start, end in parts:\n",
    "        y_non_silent.extend(y[start:end])\n",
    "\n",
    "    # Mengubah list menjadi array numpy\n",
    "    y = np.array(y_non_silent)\n",
    "    return y\n",
    "\n",
    "def preprocessing(audio):\n",
    "    y , sr = librosa.load(audio, sr=44100)\n",
    "    y = librosa.effects.preemphasis(y)\n",
    "    y = y/np.max(np.abs(y))\n",
    "    y = remove_silence(y)\n",
    "    y = nr.reduce_noise(y, sr, prop_decrease=0.8)\n",
    "    return y,sr\n",
    "\n",
    "def extraction(audio):\n",
    "    y , sr = preprocessing(audio)\n",
    "    # y = librosa.effects.preemphasis(y)\n",
    "    mfccs = librosa.feature.mfcc(y=y,\n",
    "                                 sr=sr,\n",
    "                                 n_mfcc=13,\n",
    "                                 window='hamming',\n",
    "                                 win_length=1024,\n",
    "                                 htk=True,\n",
    "                                 hop_length=512,\n",
    "                                 n_fft=1024,\n",
    "                                 norm=None,\n",
    "                                 dct_type=2,\n",
    "                                 n_mels=20)\n",
    "    # mfccs = mfccs[1:]\n",
    "    # mfccs = librosa.util.normalize(mfccs, axis=1 )\n",
    "    # return = librosa.util.normalize(mfccs.T)\n",
    "    return mfccs.T\n",
    "\n",
    "\n",
    "def apply_pca(mfcc_features, n_components):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(mfcc_features)\n",
    "    mfcc_pca = pca.transform(mfcc_features)\n",
    "    return mfcc_pca\n",
    "\n",
    "def calculate_dtw(mfccs1, mfccs2):\n",
    "    distance, _ = fastdtw(mfccs1, mfccs2, dist=cosine)\n",
    "    return distance\n",
    "\n",
    "def main(file_input, audio_name, folder_template, output_file, template_score, max_threshold_score):\n",
    "    audio_input = file_input\n",
    "    templates = os.listdir(folder_template)\n",
    "    # print(f\"len templates = {len(templates)}\")\n",
    "    total_distances = 0\n",
    "\n",
    "    with open(output_file, 'a') as f:\n",
    "        for template in templates:\n",
    "            audio_template = os.path.join(folder_template, template)\n",
    "\n",
    "            mfccs1 = extraction(audio_input)\n",
    "            mfccs2 = np.loadtxt(audio_template,delimiter=',')\n",
    "            # mfccs2 = mfccs2.T\n",
    "            # mfccs2 = mfccs2[1:]\n",
    "            # mfccs2 = mfccs2.T\n",
    "\n",
    "            # mfccs1 = apply_pca(mfccs1,10)\n",
    "            # mfccs2 = apply_pca(mfccs2,10)\n",
    "            # print(f\"mfccs1.shape = {mfccs1.shape}\")\n",
    "            # f.write(f\"mfccs1.shape = {mfccs1.shape}\")\n",
    "            # print(f\"mfccs2.shape = {mfccs2.shape}\")\n",
    "            # f.write(f\"mfccs2.shape = {mfccs2.shape}\")\n",
    "\n",
    "            dtw_distance = calculate_dtw(mfccs1, mfccs2)\n",
    "            # print(f\"dtw_distance = {dtw_distance}\")\n",
    "            # f.write(f\"dtw_distance = {dtw_distance}\")\n",
    "            total_distances += dtw_distance\n",
    "\n",
    "            # result_line = f\"Jarak DTW antara {audio_input} dan {template}: {dtw_distance}\\n\"\n",
    "            # f.write(result_line)\n",
    "\n",
    "        # Tulis hasil total jarak ke file\n",
    "        f.write(audio_name)\n",
    "        print(audio_name)\n",
    "        f.write(f\"\\nTotal Distance = {total_distances}\\n\")\n",
    "        print(f\"\\nTotal Distance = {total_distances}\\n\")\n",
    "\n",
    "        # Hitung rata-rata jarak\n",
    "        average_distance = total_distances / len(templates)\n",
    "        f.write(f\"Average Distance = {average_distance}\\n\")\n",
    "        print(f\"Average Distance = {average_distance}\\n\")\n",
    "        # # Hitung selisih antara rata-rata jarak dengan nilai template\n",
    "        # dif_distance = average_distance - template_score\n",
    "        # f.write(f\"Difference Distance = {dif_distance}\\n\")\n",
    "\n",
    "        # # Hitung skor akhir berdasarkan selisih\n",
    "        # if dif_distance <= 0:\n",
    "        #     final_score = 100\n",
    "        # elif dif_distance >= max_threshold_score:\n",
    "        #     final_score = 0\n",
    "        # else:\n",
    "        #     final_score = int(100 - ((dif_distance / max_threshold_score) * 100))\n",
    "        \n",
    "        # f.write(f\"Final Score = {final_score}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "root = \"../Dataset_MFCC_prem_norm_non_ortho/\"\n",
    "\n",
    "list_template_folders = [\n",
    "    (\"01.Ha'/\"),\n",
    "    (\"02.Kha'/\"),\n",
    "    (\"03.Shad/\"),\n",
    "    (\"04.Dhad/\"),\n",
    "    (\"05.Tha'/\"),\n",
    "    (\"06.Dhza'/\"),\n",
    "    (\"07.'AIn/\"),\n",
    "    (\"08.Ghain/\"),\n",
    "    (\"09.Qaf/\"),\n",
    "    (\"10.Ha^'/\")\n",
    "]\n",
    "# List of audio files and their names\n",
    "list_of_audio_files = [\n",
    "    (\"../Dataset/Testing_Rafi/rafi_qaf.wav\", \"rafi_qaf\"),\n",
    "    (\"../Dataset/Ridho_mic/Ridho_qaf.wav\", \"ridho_qaf\"),\n",
    "    (\"../Dataset/Dona_mic/qaf_F1_14.wav\", \"F1_qaf\"),\n",
    "    (\"../Dataset/Zahrah_mic/qaf_F2_14.wav\", \"F2_qaf\")\n",
    "]\n",
    "\n",
    "for folder in list_template_folders:\n",
    "    clear_output()\n",
    "    template_folder = os.path.join(root, folder)\n",
    "\n",
    "    output_file = f\"../fix_hasil_testing/non_ortho_prem_norm_testing_qaf_template_{folder.strip('/')}.txt\"\n",
    "\n",
    "    template_score = 23.004\n",
    "    max_threshold_score = 5\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "            f.write('')\n",
    "            f.write(f\"Banding {folder.strip('/')} dengan tester\\n\")\n",
    "    print(f\"Processing Folder = {folder.strip('/')}\")\n",
    "    # Iterate over each audio file\n",
    "    for audio_input, audio_name in list_of_audio_files:\n",
    "        main(audio_input,audio_name, template_folder, output_file, template_score, max_threshold_score)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Folder = 10.Ha^'\n",
      "rafi_Ha^'\n",
      "\n",
      "Total Distance = 262.1023207615651\n",
      "\n",
      "Average Distance = 14.561240042309173\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ini tes banding mfcc per audio langsung dtw\n",
    "\n",
    "# sr = 44100\n",
    "# n_fft = 1024 # 23ms = n_fft / sr\n",
    "# hop_length = 512 # 10ms = hop_length / sr\n",
    "import librosa\n",
    "import noisereduce as nr\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import cosine\n",
    "import os\n",
    "import numpy as np\n",
    "# from sklearn.preprocessing import MaxAbsScaler\n",
    "# from scipy.signal import butter, lfilter\n",
    "from IPython.display import clear_output\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "def remove_silence(y):\n",
    "     # Memisahkan audio menjadi bagian-bagian berdasarkan energi\n",
    "    parts = librosa.effects.split(y, top_db=25, frame_length=1024, hop_length=512)\n",
    "\n",
    "    # Menggabungkan bagian-bagian yang tidak diam\n",
    "    y_non_silent = []\n",
    "    for start, end in parts:\n",
    "        y_non_silent.extend(y[start:end])\n",
    "\n",
    "    # Mengubah list menjadi array numpy\n",
    "    y = np.array(y_non_silent)\n",
    "    return y\n",
    "\n",
    "def preprocessing(audio):\n",
    "    y , sr = librosa.load(audio, sr=44100)\n",
    "    y = librosa.effects.preemphasis(y)\n",
    "    y = y/np.max(np.abs(y))\n",
    "    y = remove_silence(y)\n",
    "    y = nr.reduce_noise(y, sr, prop_decrease=0.8)\n",
    "    return y,sr\n",
    "\n",
    "def extraction(audio):\n",
    "    y , sr = preprocessing(audio)\n",
    "    # y = librosa.effects.preemphasis(y)\n",
    "    mfccs = librosa.feature.mfcc(y=y,\n",
    "                                 sr=sr,\n",
    "                                 n_mfcc=13,\n",
    "                                 window='hamming',\n",
    "                                 win_length=1024,\n",
    "                                 htk=True,\n",
    "                                 hop_length=512,\n",
    "                                 n_fft=1024,\n",
    "                                 norm=None,\n",
    "                                 dct_type=2,\n",
    "                                 n_mels=20)\n",
    "    # mfccs = mfccs[1:]\n",
    "    # mfccs = librosa.util.normalize(mfccs, axis=1 )\n",
    "    # return = librosa.util.normalize(mfccs.T)\n",
    "    return mfccs.T\n",
    "\n",
    "def calculate_dtw(mfccs1, mfccs2):\n",
    "    distance, _ = fastdtw(mfccs1, mfccs2, dist=cosine)\n",
    "    return distance\n",
    "\n",
    "def main(file_input, audio_name, folder_template, output_file, template_score, max_threshold_score):\n",
    "    audio_input = file_input\n",
    "    templates = os.listdir(folder_template)\n",
    "    # print(f\"len templates = {len(templates)}\")\n",
    "    total_distances = 0\n",
    "\n",
    "    with open(output_file, 'a') as f:\n",
    "        for template in templates:\n",
    "            audio_template = os.path.join(folder_template, template)\n",
    "\n",
    "            mfccs1 = extraction(audio_input)\n",
    "            mfccs2 = np.loadtxt(audio_template,delimiter=',')\n",
    "            # mfccs2 = mfccs2.T\n",
    "            # mfccs2 = mfccs2[1:]\n",
    "            # mfccs2 = mfccs2.T\n",
    "\n",
    "            dtw_distance = calculate_dtw(mfccs1, mfccs2)\n",
    "            # print(f\"dtw_distance = {dtw_distance}\")\n",
    "            # f.write(f\"dtw_distance = {dtw_distance}\")\n",
    "            total_distances += dtw_distance\n",
    "\n",
    "            # result_line = f\"Jarak DTW antara {audio_input} dan {template}: {dtw_distance}\\n\"\n",
    "            # f.write(result_line)\n",
    "\n",
    "        # Tulis hasil total jarak ke file\n",
    "        f.write(audio_name)\n",
    "        print(audio_name)\n",
    "        f.write(f\"\\nTotal Distance = {total_distances}\\n\")\n",
    "        print(f\"\\nTotal Distance = {total_distances}\\n\")\n",
    "\n",
    "        # Hitung rata-rata jarak\n",
    "        average_distance = total_distances / len(templates)\n",
    "        f.write(f\"Average Distance = {average_distance}\\n\")\n",
    "        print(f\"Average Distance = {average_distance}\\n\")\n",
    "        # # Hitung selisih antara rata-rata jarak dengan nilai template\n",
    "        # dif_distance = average_distance - template_score\n",
    "        # f.write(f\"Difference Distance = {dif_distance}\\n\")\n",
    "\n",
    "        # # Hitung skor akhir berdasarkan selisih\n",
    "        # if dif_distance <= 0:\n",
    "        #     final_score = 100\n",
    "        # elif dif_distance >= max_threshold_score:\n",
    "        #     final_score = 0\n",
    "        # else:\n",
    "        #     final_score = int(100 - ((dif_distance / max_threshold_score) * 100))\n",
    "        \n",
    "        # f.write(f\"Final Score = {final_score}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "root = \"../Dataset_MFCC_prem_norm_non_ortho/\"\n",
    "\n",
    "list_template_folders = [\n",
    "    # (\"01.Ha'/\"),\n",
    "    # (\"02.Kha'/\"),\n",
    "    # (\"03.Shad/\"),\n",
    "    # (\"04.Dhad/\"),\n",
    "    # (\"05.Tha'/\"),\n",
    "    # (\"06.Dhza'/\"),\n",
    "    # (\"07.'AIn/\"),\n",
    "    # (\"08.Ghain/\"),\n",
    "    # (\"09.Qaf/\"),\n",
    "    (\"10.Ha^'/\")\n",
    "]\n",
    "# List of audio files and their names\n",
    "list_of_audio_files = [\n",
    "    (\"../Dataset/Testing_Rafi/rafi_Ha^'.wav\", \"rafi_Ha^'\"),\n",
    "    # (\"../Dataset/Ridho_mic/Ridho_Ha^'.wav\", \"ridho_Ha^'\"),\n",
    "    # (\"../Dataset/Dona_mic/Ha^'_F1_14.wav\", \"F1_Ha^'\"),\n",
    "    # (\"../Dataset/Zahrah_mic/Ha^'_F2_14.wav\", \"F2_Ha^'\")\n",
    "]\n",
    "\n",
    "for folder in list_template_folders:\n",
    "    clear_output()\n",
    "    template_folder = os.path.join(root, folder)\n",
    "\n",
    "    output_file = f\"../fix_hasil_testing/tes.txt\"\n",
    "\n",
    "    template_score = 23.004\n",
    "    max_threshold_score = 5\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "            f.write('')\n",
    "            f.write(f\"Banding {folder.strip('/')} dengan tester\\n\")\n",
    "    print(f\"Processing Folder = {folder.strip('/')}\")\n",
    "    # Iterate over each audio file\n",
    "    for audio_input, audio_name in list_of_audio_files:\n",
    "        main(audio_input,audio_name, template_folder, output_file, template_score, max_threshold_score)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bentuk dari file mfcc_Ha'_F1_11.csv: (783, 13)\n",
      "Bentuk dari file mfcc_Ha'_F1_12.csv: (814, 13)\n",
      "Bentuk dari file mfcc_Ha'_F1_13.csv: (823, 13)\n",
      "Bentuk dari file mfcc_Ha'_F2_11.csv: (760, 13)\n",
      "Bentuk dari file mfcc_Ha'_F2_12.csv: (732, 13)\n",
      "Bentuk dari file mfcc_Ha'_F2_13.csv: (762, 13)\n",
      "Bentuk dari file mfcc_Ha'_M1_11.csv: (812, 13)\n",
      "Bentuk dari file mfcc_Ha'_M1_12.csv: (762, 13)\n",
      "Bentuk dari file mfcc_Ha'_M1_13.csv: (784, 13)\n",
      "Bentuk dari file mfcc_Ha'_M2_11.csv: (783, 13)\n",
      "Bentuk dari file mfcc_Ha'_M2_12.csv: (695, 13)\n",
      "Bentuk dari file mfcc_Ha'_M2_13.csv: (719, 13)\n",
      "Bentuk dari file mfcc_Ha'_M3_1.csv: (1113, 13)\n",
      "Bentuk dari file mfcc_Ha'_M3_2.csv: (1214, 13)\n",
      "Bentuk dari file mfcc_Ha'_M3_3.csv: (1196, 13)\n",
      "Bentuk dari file mfcc_Ha'_M4_1.csv: (1158, 13)\n",
      "Bentuk dari file mfcc_Ha'_M4_2.csv: (1110, 13)\n",
      "Bentuk dari file mfcc_Ha'_M4_3.csv: (1111, 13)\n",
      "Bentuk dari file mfcc_Kha'_F1_11.csv: (830, 13)\n",
      "Bentuk dari file mfcc_Kha'_F1_12.csv: (799, 13)\n",
      "Bentuk dari file mfcc_Kha'_F1_13.csv: (797, 13)\n",
      "Bentuk dari file mfcc_Kha'_F2_11.csv: (786, 13)\n",
      "Bentuk dari file mfcc_Kha'_F2_12.csv: (810, 13)\n",
      "Bentuk dari file mfcc_Kha'_F2_13.csv: (802, 13)\n",
      "Bentuk dari file mfcc_Kha'_M1_11.csv: (857, 13)\n",
      "Bentuk dari file mfcc_Kha'_M1_12.csv: (844, 13)\n",
      "Bentuk dari file mfcc_Kha'_M1_13.csv: (861, 13)\n",
      "Bentuk dari file mfcc_Kha'_M2_11.csv: (802, 13)\n",
      "Bentuk dari file mfcc_Kha'_M2_12.csv: (818, 13)\n",
      "Bentuk dari file mfcc_Kha'_M2_13.csv: (805, 13)\n",
      "Bentuk dari file mfcc_Kha'_M3_1.csv: (1084, 13)\n",
      "Bentuk dari file mfcc_Kha'_M3_2.csv: (1131, 13)\n",
      "Bentuk dari file mfcc_Kha'_M3_3.csv: (1123, 13)\n",
      "Bentuk dari file mfcc_Kha'_M4_1.csv: (1236, 13)\n",
      "Bentuk dari file mfcc_Kha'_M4_2.csv: (1139, 13)\n",
      "Bentuk dari file mfcc_Kha'_M4_3.csv: (1105, 13)\n",
      "Bentuk dari file mfcc_Shad_F1_11.csv: (975, 13)\n",
      "Bentuk dari file mfcc_Shad_F1_12.csv: (921, 13)\n",
      "Bentuk dari file mfcc_Shad_F1_13.csv: (1010, 13)\n",
      "Bentuk dari file mfcc_Shad_F2_11.csv: (950, 13)\n",
      "Bentuk dari file mfcc_Shad_F2_12.csv: (971, 13)\n",
      "Bentuk dari file mfcc_Shad_F2_13.csv: (953, 13)\n",
      "Bentuk dari file mfcc_Shad_M1_11.csv: (920, 13)\n",
      "Bentuk dari file mfcc_Shad_M1_12.csv: (969, 13)\n",
      "Bentuk dari file mfcc_Shad_M1_13.csv: (960, 13)\n",
      "Bentuk dari file mfcc_Shad_M2_11.csv: (810, 13)\n",
      "Bentuk dari file mfcc_Shad_M2_12.csv: (839, 13)\n",
      "Bentuk dari file mfcc_Shad_M2_13.csv: (893, 13)\n",
      "Bentuk dari file mfcc_Shad_M3_1.csv: (1257, 13)\n",
      "Bentuk dari file mfcc_Shad_M3_2.csv: (1244, 13)\n",
      "Bentuk dari file mfcc_Shad_M3_3.csv: (1238, 13)\n",
      "Bentuk dari file mfcc_Shad_M4_1.csv: (1176, 13)\n",
      "Bentuk dari file mfcc_Shad_M4_2.csv: (1149, 13)\n",
      "Bentuk dari file mfcc_Shad_M4_3.csv: (1156, 13)\n",
      "Bentuk dari file mfcc_Dhad_F1_11.csv: (944, 13)\n",
      "Bentuk dari file mfcc_Dhad_F1_12.csv: (1016, 13)\n",
      "Bentuk dari file mfcc_Dhad_F1_13.csv: (1041, 13)\n",
      "Bentuk dari file mfcc_Dhad_F2_11.csv: (944, 13)\n",
      "Bentuk dari file mfcc_Dhad_F2_12.csv: (952, 13)\n",
      "Bentuk dari file mfcc_Dhad_F2_13.csv: (955, 13)\n",
      "Bentuk dari file mfcc_Dhad_M1_11.csv: (1046, 13)\n",
      "Bentuk dari file mfcc_Dhad_M1_12.csv: (985, 13)\n",
      "Bentuk dari file mfcc_Dhad_M1_13.csv: (1034, 13)\n",
      "Bentuk dari file mfcc_Dhad_M2_11.csv: (814, 13)\n",
      "Bentuk dari file mfcc_Dhad_M2_12.csv: (820, 13)\n",
      "Bentuk dari file mfcc_Dhad_M2_13.csv: (849, 13)\n",
      "Bentuk dari file mfcc_Dhad_M3_1.csv: (1280, 13)\n",
      "Bentuk dari file mfcc_Dhad_M3_2.csv: (1237, 13)\n",
      "Bentuk dari file mfcc_Dhad_M3_3.csv: (1256, 13)\n",
      "Bentuk dari file mfcc_Dhad_M4_1.csv: (1226, 13)\n",
      "Bentuk dari file mfcc_Dhad_M4_2.csv: (1205, 13)\n",
      "Bentuk dari file mfcc_Dhad_M4_3.csv: (1219, 13)\n",
      "Bentuk dari file mfcc_Tha'_F1_11.csv: (999, 13)\n",
      "Bentuk dari file mfcc_Tha'_F1_12.csv: (1012, 13)\n",
      "Bentuk dari file mfcc_Tha'_F1_13.csv: (1024, 13)\n",
      "Bentuk dari file mfcc_Tha'_F2_11.csv: (821, 13)\n",
      "Bentuk dari file mfcc_Tha'_F2_12.csv: (877, 13)\n",
      "Bentuk dari file mfcc_Tha'_F2_13.csv: (846, 13)\n",
      "Bentuk dari file mfcc_Tha'_M1_11.csv: (899, 13)\n",
      "Bentuk dari file mfcc_Tha'_M1_12.csv: (901, 13)\n",
      "Bentuk dari file mfcc_Tha'_M1_13.csv: (869, 13)\n",
      "Bentuk dari file mfcc_Tha'_M2_11.csv: (800, 13)\n",
      "Bentuk dari file mfcc_Tha'_M2_12.csv: (851, 13)\n",
      "Bentuk dari file mfcc_Tha'_M2_13.csv: (819, 13)\n",
      "Bentuk dari file mfcc_Tha'_M3_1.csv: (1105, 13)\n",
      "Bentuk dari file mfcc_Tha'_M3_2.csv: (1162, 13)\n",
      "Bentuk dari file mfcc_Tha'_M3_3.csv: (1136, 13)\n",
      "Bentuk dari file mfcc_Tha'_M4_1.csv: (1232, 13)\n",
      "Bentuk dari file mfcc_Tha'_M4_2.csv: (1225, 13)\n",
      "Bentuk dari file mfcc_Tha'_M4_3.csv: (1201, 13)\n",
      "Bentuk dari file mfcc_Dhza'_F1_11.csv: (1031, 13)\n",
      "Bentuk dari file mfcc_Dhza'_F1_12.csv: (1061, 13)\n",
      "Bentuk dari file mfcc_Dhza'_F1_13.csv: (1018, 13)\n",
      "Bentuk dari file mfcc_Dhza'_F2_11.csv: (994, 13)\n",
      "Bentuk dari file mfcc_Dhza'_F2_12.csv: (1008, 13)\n",
      "Bentuk dari file mfcc_Dhza'_F2_13.csv: (1004, 13)\n",
      "Bentuk dari file mfcc_Dhza'_M1_11.csv: (1064, 13)\n",
      "Bentuk dari file mfcc_Dhza'_M1_12.csv: (1065, 13)\n",
      "Bentuk dari file mfcc_Dhza'_M1_13.csv: (1050, 13)\n",
      "Bentuk dari file mfcc_Dhza'_M2_11.csv: (898, 13)\n",
      "Bentuk dari file mfcc_Dhza'_M2_12.csv: (835, 13)\n",
      "Bentuk dari file mfcc_Dhza'_M2_13.csv: (869, 13)\n",
      "Bentuk dari file mfcc_Dhza'_M3_1.csv: (1153, 13)\n",
      "Bentuk dari file mfcc_Dhza'_M3_2.csv: (1164, 13)\n",
      "Bentuk dari file mfcc_Dhza'_M3_3.csv: (1194, 13)\n",
      "Bentuk dari file mfcc_Dhza'_M4_1.csv: (1217, 13)\n",
      "Bentuk dari file mfcc_Dhza'_M4_2.csv: (1187, 13)\n",
      "Bentuk dari file mfcc_Dhza'_M4_3.csv: (1214, 13)\n",
      "Bentuk dari file mfcc_'Ain_F1_11.csv: (851, 13)\n",
      "Bentuk dari file mfcc_'Ain_F1_12.csv: (813, 13)\n",
      "Bentuk dari file mfcc_'Ain_F1_13.csv: (893, 13)\n",
      "Bentuk dari file mfcc_'Ain_F2_11.csv: (926, 13)\n",
      "Bentuk dari file mfcc_'Ain_F2_12.csv: (908, 13)\n",
      "Bentuk dari file mfcc_'Ain_F2_13.csv: (885, 13)\n",
      "Bentuk dari file mfcc_'Ain_M1_11.csv: (860, 13)\n",
      "Bentuk dari file mfcc_'Ain_M1_12.csv: (888, 13)\n",
      "Bentuk dari file mfcc_'Ain_M1_13.csv: (833, 13)\n",
      "Bentuk dari file mfcc_'Ain_M2_11.csv: (837, 13)\n",
      "Bentuk dari file mfcc_'Ain_M2_12.csv: (836, 13)\n",
      "Bentuk dari file mfcc_'Ain_M2_13.csv: (812, 13)\n",
      "Bentuk dari file mfcc_'Ain_M3_1.csv: (1147, 13)\n",
      "Bentuk dari file mfcc_'Ain_M3_2.csv: (1088, 13)\n",
      "Bentuk dari file mfcc_'Ain_M3_3.csv: (1160, 13)\n",
      "Bentuk dari file mfcc_'Ain_M4_1.csv: (1212, 13)\n",
      "Bentuk dari file mfcc_'Ain_M4_2.csv: (1203, 13)\n",
      "Bentuk dari file mfcc_'Ain_M4_3.csv: (1204, 13)\n",
      "Bentuk dari file mfcc_Ghain_F1_11.csv: (950, 13)\n",
      "Bentuk dari file mfcc_Ghain_F1_12.csv: (896, 13)\n",
      "Bentuk dari file mfcc_Ghain_F1_13.csv: (958, 13)\n",
      "Bentuk dari file mfcc_Ghain_F2_11.csv: (943, 13)\n",
      "Bentuk dari file mfcc_Ghain_F2_12.csv: (937, 13)\n",
      "Bentuk dari file mfcc_Ghain_F2_13.csv: (921, 13)\n",
      "Bentuk dari file mfcc_Ghain_M1_11.csv: (872, 13)\n",
      "Bentuk dari file mfcc_Ghain_M1_12.csv: (876, 13)\n",
      "Bentuk dari file mfcc_Ghain_M1_13.csv: (907, 13)\n",
      "Bentuk dari file mfcc_Ghain_M2_11.csv: (836, 13)\n",
      "Bentuk dari file mfcc_Ghain_M2_12.csv: (856, 13)\n",
      "Bentuk dari file mfcc_Ghain_M2_13.csv: (849, 13)\n",
      "Bentuk dari file mfcc_Ghain_M3_1.csv: (1115, 13)\n",
      "Bentuk dari file mfcc_Ghain_M3_2.csv: (1110, 13)\n",
      "Bentuk dari file mfcc_Ghain_M3_3.csv: (1081, 13)\n",
      "Bentuk dari file mfcc_Ghain_M4_1.csv: (1276, 13)\n",
      "Bentuk dari file mfcc_Ghain_M4_2.csv: (1331, 13)\n",
      "Bentuk dari file mfcc_Ghain_M4_3.csv: (1332, 13)\n",
      "Bentuk dari file mfcc_Qaf_F1_11.csv: (944, 13)\n",
      "Bentuk dari file mfcc_Qaf_F1_12.csv: (989, 13)\n",
      "Bentuk dari file mfcc_Qaf_F1_13.csv: (927, 13)\n",
      "Bentuk dari file mfcc_Qaf_F2_11.csv: (927, 13)\n",
      "Bentuk dari file mfcc_Qaf_F2_12.csv: (948, 13)\n",
      "Bentuk dari file mfcc_Qaf_F2_13.csv: (915, 13)\n",
      "Bentuk dari file mfcc_Qaf_M1_11.csv: (903, 13)\n",
      "Bentuk dari file mfcc_Qaf_M1_12.csv: (948, 13)\n",
      "Bentuk dari file mfcc_Qaf_M1_13.csv: (873, 13)\n",
      "Bentuk dari file mfcc_Qaf_M2_11.csv: (766, 13)\n",
      "Bentuk dari file mfcc_Qaf_M2_12.csv: (846, 13)\n",
      "Bentuk dari file mfcc_Qaf_M2_13.csv: (812, 13)\n",
      "Bentuk dari file mfcc_Qaf_M3_1.csv: (1089, 13)\n",
      "Bentuk dari file mfcc_Qaf_M3_2.csv: (1106, 13)\n",
      "Bentuk dari file mfcc_Qaf_M3_3.csv: (1085, 13)\n",
      "Bentuk dari file mfcc_Qaf_M4_1.csv: (1276, 13)\n",
      "Bentuk dari file mfcc_Qaf_M4_2.csv: (1251, 13)\n",
      "Bentuk dari file mfcc_Qaf_M4_3.csv: (1230, 13)\n",
      "Bentuk dari file mfcc_Ha^'_F1_11.csv: (785, 13)\n",
      "Bentuk dari file mfcc_Ha^'_F1_12.csv: (862, 13)\n",
      "Bentuk dari file mfcc_Ha^'_F1_13.csv: (814, 13)\n",
      "Bentuk dari file mfcc_Ha^'_F2_11.csv: (877, 13)\n",
      "Bentuk dari file mfcc_Ha^'_F2_12.csv: (862, 13)\n",
      "Bentuk dari file mfcc_Ha^'_F2_13.csv: (853, 13)\n",
      "Bentuk dari file mfcc_Ha^'_M1_11.csv: (909, 13)\n",
      "Bentuk dari file mfcc_Ha^'_M1_12.csv: (907, 13)\n",
      "Bentuk dari file mfcc_Ha^'_M1_13.csv: (930, 13)\n",
      "Bentuk dari file mfcc_Ha^'_M2_11.csv: (811, 13)\n",
      "Bentuk dari file mfcc_Ha^'_M2_12.csv: (815, 13)\n",
      "Bentuk dari file mfcc_Ha^'_M2_13.csv: (817, 13)\n",
      "Bentuk dari file mfcc_Ha^'_M3_1.csv: (1008, 13)\n",
      "Bentuk dari file mfcc_Ha^'_M3_2.csv: (1004, 13)\n",
      "Bentuk dari file mfcc_Ha^'_M3_3.csv: (1045, 13)\n",
      "Bentuk dari file mfcc_Ha^'_M4_1.csv: (1261, 13)\n",
      "Bentuk dari file mfcc_Ha^'_M4_2.csv: (1258, 13)\n",
      "Bentuk dari file mfcc_Ha^'_M4_3.csv: (1371, 13)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "root = \"../Dataset_MFCC/\"\n",
    "\n",
    "list_template_folders = [\n",
    "    \"01.Ha'/\",\n",
    "    \"02.Kha'/\",\n",
    "    \"03.Shad/\",\n",
    "    \"04.Dhad/\",\n",
    "    \"05.Tha'/\",\n",
    "    \"06.Dhza'/\",\n",
    "    \"07.'AIn/\",\n",
    "    \"08.Ghain/\",\n",
    "    \"09.Qaf/\",\n",
    "    \"10.Ha^'/\"\n",
    "]\n",
    "\n",
    "for folderx in list_template_folders:\n",
    "    foldernya = os.path.join(root, folderx)\n",
    "    files = os.listdir(foldernya)\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            csv_filenya= np.loadtxt(os.path.join(foldernya, file), delimiter=',')\n",
    "            print(f\"Bentuk dari file {file}: {csv_filenya.shape}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
